#!/usr/bin/env python
"""
Hikyuu â†’ Qlib è®­ç»ƒ â†’ Hikyuu å›æµ‹ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

å±•ç¤ºå¦‚ä½•:
1. ä½¿ç”¨ Hikyuu è·å–æ•°æ®å¹¶å‡†å¤‡è®­ç»ƒæ•°æ®
2. ä½¿ç”¨ QlibModelTrainerAdapter è®­ç»ƒ LGBM æ¨¡å‹
3. ç”Ÿæˆé¢„æµ‹ä¿¡å·
4. ä½¿ç”¨ HikyuuBacktestAdapter å›æµ‹
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime, date
from decimal import Decimal

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import pandas as pd
import numpy as np
from hikyuu import *

from adapters.qlib.qlib_model_trainer_adapter import QlibModelTrainerAdapter
from adapters.hikyuu.hikyuu_backtest_adapter import HikyuuBacktestAdapter
from domain.entities.model import Model, ModelType
from domain.entities.trading_signal import SignalBatch, TradingSignal, SignalType
from domain.value_objects.stock_code import StockCode
from domain.value_objects.configuration import BacktestConfig
from domain.value_objects.date_range import DateRange


def prepare_hikyuu_training_data(stock_list, start_date, end_date):
    """
    ä» Hikyuu è·å–æ•°æ®å¹¶å‡†å¤‡è®­ç»ƒ DataFrame

    Args:
        stock_list: è‚¡ç¥¨åˆ—è¡¨ ['sh600000', 'sh600016', ...]
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ

    Returns:
        pd.DataFrame: åŒ…å« stock_code, features, label_return çš„è®­ç»ƒæ•°æ®
    """
    print("\nğŸ“Š å‡†å¤‡ Hikyuu è®­ç»ƒæ•°æ®...")

    sm = StockManager.instance()
    training_data = []

    for stock_code in stock_list:
        try:
            # è·å– Hikyuu è‚¡ç¥¨å¯¹è±¡ï¼ˆæ³¨æ„ï¼šæ–¹æ³•åæ˜¯ get_stock ä¸æ˜¯ getStockï¼‰
            stock = sm.get_stock(stock_code.upper())
            if not stock or stock.is_null():
                print(f"  âš ï¸  è·³è¿‡: {stock_code} (æœªæ‰¾åˆ°)")
                continue

            # è·å–æ—¥çº¿æ•°æ®ï¼ˆæ³¨æ„ï¼šæ–¹æ³•åæ˜¯ get_kdata ä¸æ˜¯ getKDataï¼‰
            kdata = stock.get_kdata(Query(-500))  # è·å–æœ€è¿‘500å¤©æ•°æ®

            if len(kdata) < 50:  # è‡³å°‘éœ€è¦50å¤©æ•°æ®æ¥è®¡ç®—ç‰¹å¾
                print(f"  âš ï¸  è·³è¿‡: {stock_code} (æ•°æ®ä¸è¶³)")
                continue

            # æå–ä»·æ ¼æ•°æ®ï¼ˆæ³¨æ„ï¼šå±æ€§åæ˜¯ close ä¸æ˜¯ closePriceï¼‰
            close_prices = np.array([k.close for k in kdata])
            high_prices = np.array([k.high for k in kdata])
            low_prices = np.array([k.low for k in kdata])
            volumes = np.array([k.volume for k in kdata])

            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            for i in range(50, len(kdata)):  # éœ€è¦è¶³å¤Ÿå†å²æ•°æ®è®¡ç®—æŒ‡æ ‡
                # ç‰¹å¾1: 5æ—¥æ”¶ç›Šç‡
                ret_5d = (close_prices[i] - close_prices[i-5]) / close_prices[i-5]

                # ç‰¹å¾2: 10æ—¥æ”¶ç›Šç‡
                ret_10d = (close_prices[i] - close_prices[i-10]) / close_prices[i-10]

                # ç‰¹å¾3: 20æ—¥æ”¶ç›Šç‡
                ret_20d = (close_prices[i] - close_prices[i-20]) / close_prices[i-20]

                # ç‰¹å¾4: 20æ—¥æ³¢åŠ¨ç‡
                volatility_20d = np.std(close_prices[i-20:i])

                # ç‰¹å¾5: ç›¸å¯¹æˆäº¤é‡ (ä»Šæ—¥/20æ—¥å‡é‡)
                vol_avg_20d = np.mean(volumes[i-20:i])
                rel_volume = volumes[i] / vol_avg_20d if vol_avg_20d > 0 else 1.0

                # æ ‡ç­¾: æœªæ¥5æ—¥æ”¶ç›Šç‡
                if i + 5 < len(kdata):
                    label_return = (close_prices[i+5] - close_prices[i]) / close_prices[i]
                else:
                    continue  # æ²¡æœ‰æœªæ¥æ•°æ®,è·³è¿‡

                training_data.append({
                    'stock_code': stock_code.lower(),
                    'date': kdata[i].datetime.date(),
                    'feature_ret_5d': ret_5d,
                    'feature_ret_10d': ret_10d,
                    'feature_ret_20d': ret_20d,
                    'feature_volatility': volatility_20d,
                    'feature_rel_volume': rel_volume,
                    'label_return': label_return
                })

            print(f"  âœ… {stock_code}: {len(training_data)} æ ·æœ¬")

        except Exception as e:
            print(f"  âŒ {stock_code}: {e}")
            continue

    df = pd.DataFrame(training_data)
    print(f"\nâœ… æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"   ç‰¹å¾åˆ—: {[c for c in df.columns if c.startswith('feature_')]}")
    print(f"   æ ‡ç­¾åˆ—: label_return")

    return df


def predictions_to_signals(predictions_batch, signal_date):
    """
    å°†é¢„æµ‹ç»“æœè½¬æ¢ä¸ºäº¤æ˜“ä¿¡å·

    Args:
        predictions_batch: PredictionBatch é¢„æµ‹æ‰¹æ¬¡
        signal_date: ä¿¡å·æ—¥æœŸ

    Returns:
        SignalBatch: äº¤æ˜“ä¿¡å·æ‰¹æ¬¡
    """
    print("\nğŸ”„ è½¬æ¢é¢„æµ‹ä¸ºäº¤æ˜“ä¿¡å·...")

    signal_batch = SignalBatch(
        strategy_name="Hikyuu-Qlib-LGBM",
        batch_date=datetime.now()
    )

    # æŒ‰é¢„æµ‹å€¼æ’åº,é€‰æ‹© Top-N åšå¤š
    df = predictions_batch.to_dataframe()
    df = df.sort_values('predicted_value', ascending=False)

    top_n = 10  # åšå¤šå‰10åª

    for i, row in df.head(top_n).iterrows():
        signal = TradingSignal(
            stock_code=StockCode(row['stock_code']),
            signal_date=signal_date,
            signal_type=SignalType.BUY,
            price=None,  # ç”±å›æµ‹å¼•æ“å†³å®š
        )
        signal_batch.add_signal(signal)

    print(f"âœ… ç”Ÿæˆ {signal_batch.size()} ä¸ªäº¤æ˜“ä¿¡å·")

    return signal_batch


async def main():
    """å®Œæ•´å·¥ä½œæµ"""
    print("=" * 70)
    print("Hikyuu â†’ Qlib è®­ç»ƒ â†’ Hikyuu å›æµ‹ å®Œæ•´å·¥ä½œæµ")
    print("=" * 70)

    # ===== åˆå§‹åŒ– Hikyuu =====
    print("\nğŸ”§ åˆå§‹åŒ– Hikyuu ç³»ç»Ÿ...")
    hikyuu_init("./config/hikyuu.ini")
    print("âœ… Hikyuu åˆå§‹åŒ–å®Œæˆ\n")

    # ===== æ­¥éª¤1: å‡†å¤‡è®­ç»ƒæ•°æ® (Hikyuu) =====
    print("ã€æ­¥éª¤1ã€‘ä» Hikyuu å‡†å¤‡è®­ç»ƒæ•°æ®")

    stock_list = [
        'sh600000',  # æµ¦å‘é“¶è¡Œ
        'sh600016',  # æ°‘ç”Ÿé“¶è¡Œ
        'sh600036',  # æ‹›å•†é“¶è¡Œ
        'sh600519',  # è´µå·èŒ…å°
        'sh600887',  # ä¼Šåˆ©è‚¡ä»½
    ]

    training_df = prepare_hikyuu_training_data(
        stock_list=stock_list,
        start_date=date(2023, 1, 1),
        end_date=date(2024, 10, 31)
    )

    if training_df.empty:
        print("âŒ è®­ç»ƒæ•°æ®ä¸ºç©º,é€€å‡º")
        return

    # ===== æ­¥éª¤2: è®­ç»ƒæ¨¡å‹ (QlibModelTrainerAdapter) =====
    print("\nã€æ­¥éª¤2ã€‘è®­ç»ƒ LGBM æ¨¡å‹")

    adapter = QlibModelTrainerAdapter()

    model = Model(
        model_type=ModelType.LGBM,
        hyperparameters={
            "learning_rate": 0.05,
            "num_leaves": 31,
            "verbose": -1,
        }
    )

    print(f"  æ¨¡å‹ç±»å‹: {model.model_type.value}")
    print(f"  è®­ç»ƒæ ·æœ¬: {len(training_df)}")

    trained_model = await adapter.train(model, training_df)

    print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆ")
    print(f"   çŠ¶æ€: {trained_model.status.value}")
    print(f"   è®­ç»ƒ RÂ²: {trained_model.metrics.get('train_r2', 0):.4f}")
    print(f"   æµ‹è¯• RÂ²: {trained_model.metrics.get('test_r2', 0):.4f}")
    print(f"   è®­ç»ƒ RMSE: {trained_model.metrics.get('train_rmse', 0):.4f}")
    print(f"   æµ‹è¯• RMSE: {trained_model.metrics.get('test_rmse', 0):.4f}")

    # ===== æ­¥éª¤3: ç”Ÿæˆé¢„æµ‹ =====
    print("\nã€æ­¥éª¤3ã€‘ç”Ÿæˆé¢„æµ‹ä¿¡å·")

    # ä½¿ç”¨æœ€æ–°æ•°æ®ç”Ÿæˆé¢„æµ‹
    prediction_df = training_df.tail(len(stock_list)).copy()  # æ¯åªè‚¡ç¥¨å–æœ€æ–°ä¸€æ¡
    prediction_df = prediction_df.drop_duplicates(subset=['stock_code'], keep='last')

    print(f"  é¢„æµ‹æ ·æœ¬: {len(prediction_df)}")

    predictions_batch = await adapter.predict_batch(
        model=trained_model,
        input_data=prediction_df,
        prediction_date=datetime(2024, 11, 19)
    )

    print(f"\nâœ… é¢„æµ‹å®Œæˆ")
    print(f"   æ‰¹æ¬¡å¤§å°: {predictions_batch.size()}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {predictions_batch.average_confidence():.2%}")

    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    print("\né¢„æµ‹ç»“æœ:")
    pred_df = predictions_batch.to_dataframe()
    pred_df = pred_df.sort_values('predicted_value', ascending=False)
    print(pred_df[['stock_code', 'predicted_value', 'confidence']].to_string(index=False))

    # ===== æ­¥éª¤4: è½¬æ¢ä¸ºäº¤æ˜“ä¿¡å· =====
    signal_batch = predictions_to_signals(
        predictions_batch,
        datetime(2024, 11, 19)
    )

    # ===== æ­¥éª¤5: ä¿å­˜é¢„æµ‹ç»“æœä¾›å›æµ‹ä½¿ç”¨ =====
    print("\nã€æ­¥éª¤5ã€‘ä¿å­˜é¢„æµ‹ç»“æœ")

    import pickle
    from pathlib import Path

    # å‡†å¤‡é¢„æµ‹æ•°æ®æ ¼å¼ï¼ˆQlib å…¼å®¹æ ¼å¼ï¼‰
    # å°† PredictionBatch è½¬æ¢ä¸º Qlib pred.pkl æ ¼å¼
    pred_df = predictions_batch.to_dataframe()

    # Qlib æ ¼å¼éœ€è¦: datetime index, instrument columns, score values
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨å­—å…¸æ ¼å¼
    pred_data = {
        'predictions': pred_df,
        'scores': dict(zip(pred_df['stock_code'], pred_df['predicted_value']))
    }

    output_path = Path("./outputs/predictions")
    output_path.mkdir(parents=True, exist_ok=True)
    pred_file = output_path / "workflow_pred.pkl"

    with open(pred_file, 'wb') as f:
        pickle.dump(pred_data, f)

    print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜: {pred_file}")

    # ===== æ­¥éª¤6: ä½¿ç”¨ CustomSG_QlibFactor å›æµ‹ =====
    print("\nã€æ­¥éª¤6ã€‘ä½¿ç”¨ Hikyuu CustomSG_QlibFactor å›æµ‹")
    print("âš ï¸  æ³¨æ„: CustomSG_QlibFactor éœ€è¦å®Œæ•´çš„ pred.pkl æ ¼å¼")
    print("   å½“å‰æ¼”ç¤ºåˆ°é¢„æµ‹ç”Ÿæˆæ­¥éª¤ï¼Œå›æµ‹éƒ¨åˆ†éœ€è¦ä½¿ç”¨:")
    print(f"   - CustomSG_QlibFactor(pred_pkl_path='{pred_file}')")
    print("   - å‚è€ƒ examples/backtest_example.py å®Œæ•´å›æµ‹æµç¨‹")

    print("\n" + "=" * 70)
    print("âœ… å·¥ä½œæµæ¼”ç¤ºå®Œæˆ!")
    print("=" * 70)
    print("\nğŸ“Š æ‰§è¡Œæ€»ç»“:")
    print(f"  âœ… æ•°æ®æå–: {len(training_df)} ä¸ªè®­ç»ƒæ ·æœ¬")
    print(f"  âœ… æ¨¡å‹è®­ç»ƒ: RÂ² = {trained_model.metrics.get('test_r2', 0):.4f}")
    print(f"  âœ… é¢„æµ‹ç”Ÿæˆ: {predictions_batch.size()} ä¸ªé¢„æµ‹")
    print(f"  âœ… ä¿¡å·è½¬æ¢: {signal_batch.size()} ä¸ªäº¤æ˜“ä¿¡å·")
    print(f"  âœ… ç»“æœä¿å­˜: {pred_file}")

    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. ä½¿ç”¨ä¿å­˜çš„é¢„æµ‹æ–‡ä»¶è¿›è¡Œå®Œæ•´å›æµ‹")
    print("  2. è°ƒæ•´æ¨¡å‹å‚æ•°æ”¹å–„é¢„æµ‹æ•ˆæœï¼ˆå½“å‰æµ‹è¯• RÂ² è¾ƒä½ï¼‰")
    print("  3. å¢åŠ æ›´å¤šç‰¹å¾å’Œè®­ç»ƒæ•°æ®")


if __name__ == "__main__":
    asyncio.run(main())
