"""
æ¨¡å‹è®­ç»ƒæ•°æ®åŠ è½½æµç¨‹ - è®¾è®¡æ–¹æ¡ˆ

è¿™ä¸ªæ–‡æ¡£å±•ç¤ºå¦‚ä½•é›†æˆæ•°æ®åŠ è½½åˆ°æ¨¡å‹è®­ç»ƒæµç¨‹ä¸­
"""

from datetime import datetime
from typing import Optional, List, Any
import pandas as pd

from domain.value_objects.stock_code import StockCode
from domain.value_objects.date_range import DateRange
from domain.value_objects.kline_type import KLineType
from domain.entities.kline_data import KLineData
from domain.entities.model import Model, ModelType


# ============================================================================
# æ–¹æ¡ˆA: trainå‘½ä»¤é›†æˆæ•°æ®åŠ è½½ï¼ˆæ¨èç”¨äºå¿«é€Ÿå®éªŒï¼‰
# ============================================================================

async def train_with_integrated_data_loading(
    container,
    model_type: ModelType,
    name: str,
    # æ•°æ®æ¥æºé€‰é¡¹1: ä»Hikyuu/Qlibå®æ—¶åŠ è½½
    stock_code: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    # æ•°æ®æ¥æºé€‰é¡¹2: ä»æ–‡ä»¶åŠ è½½
    data_file: Optional[str] = None,
    # æ•°æ®æ¥æºé€‰é¡¹3: ä»æ•°æ®åº“åŠ è½½
    use_cached_data: bool = False,
):
    """
    é›†æˆæ•°æ®åŠ è½½çš„è®­ç»ƒæµç¨‹

    æ”¯æŒä¸‰ç§æ•°æ®æ¥æº:
    1. å®æ—¶ä»Hikyuu/QlibåŠ è½½
    2. ä»CSV/Parquetæ–‡ä»¶åŠ è½½
    3. ä»æ•°æ®åº“ç¼“å­˜åŠ è½½
    """

    # æ­¥éª¤1: åŠ è½½è®­ç»ƒæ•°æ®
    training_data = None

    if stock_code and start_date and end_date:
        # é€‰é¡¹1: å®æ—¶åŠ è½½
        print(f"ğŸ“Š ä»HikyuuåŠ è½½æ•°æ®: {stock_code} ({start_date} ~ {end_date})")

        load_data_use_case = container.load_stock_data_use_case
        kline_data = await load_data_use_case.execute(
            stock_code=StockCode(stock_code),
            date_range=DateRange(
                start_date=datetime.strptime(start_date, "%Y-%m-%d"),
                end_date=datetime.strptime(end_date, "%Y-%m-%d")
            ),
            kline_type=KLineType.DAY
        )

        # è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
        training_data = convert_kline_to_training_data(kline_data)
        print(f"âœ… åŠ è½½å®Œæˆ: {len(training_data)} æ¡è®°å½•")

    elif data_file:
        # é€‰é¡¹2: ä»æ–‡ä»¶åŠ è½½
        print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½æ•°æ®: {data_file}")
        training_data = load_from_file(data_file)
        print(f"âœ… åŠ è½½å®Œæˆ: {len(training_data)} æ¡è®°å½•")

    elif use_cached_data:
        # é€‰é¡¹3: ä»æ•°æ®åº“åŠ è½½ï¼ˆä¹‹å‰ä¿å­˜çš„æ•°æ®ï¼‰
        print(f"ğŸ’¾ ä»ç¼“å­˜åŠ è½½æ•°æ®...")
        # TODO: å®ç°æ•°æ®åº“ç¼“å­˜è¯»å–
        raise NotImplementedError("Database cache not yet implemented")

    else:
        raise ValueError("å¿…é¡»æä¾›æ•°æ®æº: --code + --start + --end æˆ– --data-file")

    # æ­¥éª¤2: åˆ›å»ºæ¨¡å‹å®ä½“
    model = Model(
        model_type=model_type,
        hyperparameters={"learning_rate": 0.01, "max_depth": 6}
    )

    # æ­¥éª¤3: è®­ç»ƒæ¨¡å‹
    print(f"ğŸ¤– å¼€å§‹è®­ç»ƒ {model_type.value} æ¨¡å‹...")
    train_use_case = container.train_model_use_case
    trained_model = await train_use_case.execute(
        model=model,
        training_data=training_data
    )

    print(f"âœ… è®­ç»ƒå®Œæˆ!")
    print(f"   æ¨¡å‹ID: {trained_model.id}")
    print(f"   çŠ¶æ€: {trained_model.status.value}")
    if trained_model.metrics:
        print(f"   æŒ‡æ ‡: {trained_model.metrics}")

    return trained_model


# ============================================================================
# æ–¹æ¡ˆB: åˆ†ç¦»çš„æ•°æ®åŠ è½½å’Œè®­ç»ƒï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
# ============================================================================

async def load_and_save_training_data(
    container,
    stock_code: str,
    start_date: str,
    end_date: str,
    output_file: str,
):
    """
    åŠ è½½æ•°æ®å¹¶ä¿å­˜åˆ°æ–‡ä»¶

    ç”¨æ³•:
        data load --code sh600000 --start 2023-01-01 --end 2023-12-31 --output train.csv
    """
    print(f"ğŸ“Š åŠ è½½æ•°æ®: {stock_code} ({start_date} ~ {end_date})")

    # 1. åŠ è½½Kçº¿æ•°æ®
    load_data_use_case = container.load_stock_data_use_case
    kline_data = await load_data_use_case.execute(
        stock_code=StockCode(stock_code),
        date_range=DateRange(
            start_date=datetime.strptime(start_date, "%Y-%m-%d"),
            end_date=datetime.strptime(end_date, "%Y-%m-%d")
        ),
        kline_type=KLineType.DAY
    )

    # 2. è½¬æ¢ä¸ºDataFrame
    df = kline_data_to_dataframe(kline_data)

    # 3. ç‰¹å¾å·¥ç¨‹ï¼ˆå¯é€‰ï¼‰
    df = add_technical_indicators(df)

    # 4. ä¿å­˜åˆ°æ–‡ä»¶
    df.to_csv(output_file, index=False)
    print(f"âœ… æ•°æ®å·²ä¿å­˜: {output_file} ({len(df)} æ¡è®°å½•)")

    return output_file


async def train_from_saved_data(
    container,
    model_type: ModelType,
    name: str,
    data_file: str,
):
    """
    ä½¿ç”¨å·²ä¿å­˜çš„æ•°æ®è®­ç»ƒæ¨¡å‹

    ç”¨æ³•:
        model train --type LGBM --name my_model --data train.csv
    """
    print(f"ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®: {data_file}")

    # 1. ä»æ–‡ä»¶åŠ è½½
    training_data = load_from_file(data_file)
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(training_data)} æ¡è®°å½•")

    # 2. åˆ›å»ºæ¨¡å‹
    model = Model(
        model_type=model_type,
        hyperparameters={"learning_rate": 0.01}
    )

    # 3. è®­ç»ƒ
    print(f"ğŸ¤– å¼€å§‹è®­ç»ƒ...")
    train_use_case = container.train_model_use_case
    trained_model = await train_use_case.execute(
        model=model,
        training_data=training_data
    )

    print(f"âœ… è®­ç»ƒå®Œæˆ!")
    return trained_model


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def convert_kline_to_training_data(kline_data: List[KLineData]) -> Any:
    """
    å°†Kçº¿æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ ¼å¼

    è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹éœ€æ±‚å®ç°ï¼Œä¾‹å¦‚:
    - LightGBM: éœ€è¦DataFrameæ ¼å¼
    - PyTorch: éœ€è¦Tensoræ ¼å¼
    - Sklearn: éœ€è¦numpyæ•°ç»„
    """
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame([
        {
            'date': kline.timestamp,
            'open': float(kline.open),
            'high': float(kline.high),
            'low': float(kline.low),
            'close': float(kline.close),
            'volume': kline.volume,
            'amount': float(kline.amount) if kline.amount else 0,
        }
        for kline in kline_data
    ])

    # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ä½œä¸ºç‰¹å¾
    df = add_technical_indicators(df)

    # æ·»åŠ æ ‡ç­¾ï¼ˆä¾‹å¦‚ï¼šæœªæ¥æ”¶ç›Šç‡ï¼‰
    df = add_labels(df)

    return df


def kline_data_to_dataframe(kline_data: List[KLineData]) -> pd.DataFrame:
    """Kçº¿æ•°æ®è½¬DataFrame"""
    return pd.DataFrame([
        {
            'timestamp': kline.timestamp,
            'stock_code': kline.stock_code.value,
            'open': float(kline.open),
            'high': float(kline.high),
            'low': float(kline.low),
            'close': float(kline.close),
            'volume': kline.volume,
            'amount': float(kline.amount) if kline.amount else 0,
        }
        for kline in kline_data
    ])


def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾

    ä¾‹å¦‚: MA, MACD, RSI, Bollinger Bandsç­‰
    """
    # ç§»åŠ¨å¹³å‡çº¿
    df['ma5'] = df['close'].rolling(window=5).mean()
    df['ma10'] = df['close'].rolling(window=10).mean()
    df['ma20'] = df['close'].rolling(window=20).mean()

    # æ”¶ç›Šç‡
    df['return'] = df['close'].pct_change()

    # æ³¢åŠ¨ç‡
    df['volatility'] = df['return'].rolling(window=20).std()

    # æˆäº¤é‡å˜åŒ–
    df['volume_change'] = df['volume'].pct_change()

    return df


def add_labels(df: pd.DataFrame, horizon: int = 1) -> pd.DataFrame:
    """
    æ·»åŠ è®­ç»ƒæ ‡ç­¾

    Args:
        horizon: é¢„æµ‹æœªæ¥å¤šå°‘å¤©çš„æ”¶ç›Š
    """
    # æœªæ¥æ”¶ç›Šç‡ä½œä¸ºæ ‡ç­¾
    df['label'] = df['close'].shift(-horizon) / df['close'] - 1

    # æˆ–è€…åˆ†ç±»æ ‡ç­¾ (æ¶¨/è·Œ)
    df['label_class'] = (df['label'] > 0).astype(int)

    return df


def load_from_file(file_path: str) -> Any:
    """ä»æ–‡ä»¶åŠ è½½è®­ç»ƒæ•°æ®"""
    if file_path.endswith('.csv'):
        return pd.read_csv(file_path)
    elif file_path.endswith('.parquet'):
        return pd.read_parquet(file_path)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")


# ============================================================================
# CLIå‘½ä»¤ç¤ºä¾‹
# ============================================================================

"""
æ–¹æ¡ˆAä½¿ç”¨ç¤ºä¾‹ï¼ˆé›†æˆæ–¹å¼ï¼‰:
---------------------------------

# ç›´æ¥ä»HikyuuåŠ è½½å¹¶è®­ç»ƒ
./run_cli.sh model train \\
    --type LGBM \\
    --name my_model \\
    --code sh600000 \\
    --start 2023-01-01 \\
    --end 2023-12-31

# æˆ–ä»æ–‡ä»¶è®­ç»ƒ
./run_cli.sh model train \\
    --type LGBM \\
    --name my_model \\
    --data-file train_data.csv


æ–¹æ¡ˆBä½¿ç”¨ç¤ºä¾‹ï¼ˆåˆ†ç¦»æ–¹å¼ï¼‰:
---------------------------------

# æ­¥éª¤1: åŠ è½½å¹¶ä¿å­˜æ•°æ®
./run_cli.sh data load \\
    --code sh600000 \\
    --start 2023-01-01 \\
    --end 2023-12-31 \\
    --output train_data.csv

# æ­¥éª¤2: ä½¿ç”¨ä¿å­˜çš„æ•°æ®è®­ç»ƒ
./run_cli.sh model train \\
    --type LGBM \\
    --name my_model \\
    --data train_data.csv

# ä¼˜ç‚¹: æ•°æ®å¯é‡ç”¨ï¼Œè®­ç»ƒå¤šä¸ªæ¨¡å‹
./run_cli.sh model train --type MLP --name mlp_model --data train_data.csv
./run_cli.sh model train --type LSTM --name lstm_model --data train_data.csv
"""


# ============================================================================
# æ¨èæ–¹æ¡ˆï¼šæ··åˆæ–¹å¼
# ============================================================================

"""
åŒæ—¶æ”¯æŒä¸¤ç§æ–¹å¼ï¼Œè®©ç”¨æˆ·é€‰æ‹©:

1. å¿«é€Ÿå®éªŒ: ä¸€æ¡å‘½ä»¤å®Œæˆï¼ˆæ–¹æ¡ˆAï¼‰
   ./run_cli.sh model train --type LGBM --name quick_test --code sh600000 --start 2023-01-01 --end 2023-12-31

2. ç”Ÿäº§æµç¨‹: æ•°æ®å¤ç”¨ï¼ˆæ–¹æ¡ˆBï¼‰
   ./run_cli.sh data load --code sh600000 --start 2020-01-01 --end 2023-12-31 --output prod_data.csv
   ./run_cli.sh model train --type LGBM --name prod_model --data prod_data.csv

3. æ‰¹é‡è®­ç»ƒ: é¢„å…ˆå‡†å¤‡å¤šä¸ªæ•°æ®é›†
   ./run_cli.sh data load --code sh600000 --start 2020-01-01 --end 2023-12-31 --output sh600000.csv
   ./run_cli.sh data load --code sz000001 --start 2020-01-01 --end 2023-12-31 --output sz000001.csv

   # å¯¹æ¯ä¸ªè‚¡ç¥¨è®­ç»ƒæ¨¡å‹
   for stock in sh600000 sz000001; do
       ./run_cli.sh model train --type LGBM --name ${stock}_model --data ${stock}.csv
   done
"""
