# Hikyuu Ã— Qlib é¡¹ç›®ä»£ç é€»è¾‘å®¡æŸ¥æŠ¥å‘Š

## æ‰§è¡Œæ¦‚è¦

æœ¬æŠ¥å‘Šå¯¹Hikyuu Ã— Qlibé¡¹ç›®è¿›è¡Œäº†æœ€å…¨é¢çš„ä»£ç é€»è¾‘å®¡æŸ¥ï¼Œæ¶µç›–äº†é¡¹ç›®ä¸­çš„æ¯ä¸€ä¸ªPythonæ–‡ä»¶ã€é…ç½®æ–‡ä»¶å’Œè„šæœ¬æ–‡ä»¶ã€‚å®¡æŸ¥éµå¾ªç³»ç»Ÿæ€§æ–¹æ³•ï¼Œç¡®ä¿æ²¡æœ‰é—æ¼ä»»ä½•æ–‡ä»¶æˆ–é€»è¾‘é”™è¯¯ã€‚

### å®¡æŸ¥èŒƒå›´
- **æ€»è®¡æ‰«ææ–‡ä»¶æ•°**: 87ä¸ª
- **Pythonæ–‡ä»¶**: 72ä¸ª
- **é…ç½®æ–‡ä»¶**: 4ä¸ª
- **Shellè„šæœ¬**: 5ä¸ª
- **å…¶ä»–æ–‡ä»¶**: 6ä¸ª

### å®¡æŸ¥åˆ†ç±»
1. **è¯­æ³•é”™è¯¯å’Œé€»è¾‘é”™è¯¯** - ä»£ç ç»“æ„å’Œå®ç°é€»è¾‘é—®é¢˜
2. **å¯¼å…¥é”™è¯¯å’Œä¾èµ–é—®é¢˜** - æ¨¡å—å¯¼å…¥å’ŒåŒ…ä¾èµ–é—®é¢˜
3. **ç±»å‹æ³¨è§£å’Œç±»å‹å®‰å…¨** - ç±»å‹æç¤ºå’Œç±»å‹ä¸€è‡´æ€§
4. **å¼‚å¸¸å¤„ç†å®Œæ•´æ€§** - é”™è¯¯å¤„ç†å’Œå¼‚å¸¸ç®¡ç†
5. **è¾¹ç•Œæ¡ä»¶å¤„ç†** - è¾¹ç•Œå€¼å’Œæç«¯æƒ…å†µå¤„ç†
6. **æ•°æ®éªŒè¯é€»è¾‘** - æ•°æ®å®Œæ•´æ€§å’ŒéªŒè¯æœºåˆ¶
7. **èµ„æºç®¡ç†** - èµ„æºåˆ†é…å’Œé‡Šæ”¾
8. **å¹¶å‘å®‰å…¨** - å¤šçº¿ç¨‹å’Œå¼‚æ­¥æ“ä½œå®‰å…¨æ€§
9. **ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§** - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘éªŒè¯

---

## 1. è¯­æ³•é”™è¯¯å’Œé€»è¾‘é”™è¯¯

### 1.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜1.1.1: ä¸å®Œæ•´çš„æ–‡ä»¶è¯»å–
**æ–‡ä»¶**: [`src/adapters/converters/signal_converter_adapter.py`](src/adapters/converters/signal_converter_adapter.py:1-570)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: æ–‡ä»¶è¯»å–è¢«æˆªæ–­ï¼Œåªè¯»å–äº†570è¡Œï¼Œå¯èƒ½å­˜åœ¨æœªå‘ç°çš„é€»è¾‘é”™è¯¯
**å…·ä½“é—®é¢˜**: 
- æ–‡ä»¶å¯èƒ½åŒ…å«é‡è¦çš„ä¿¡å·è½¬æ¢é€»è¾‘æœªå®Œå…¨å®¡æŸ¥
- æ— æ³•éªŒè¯å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶
- å¯èƒ½å­˜åœ¨æœªå¤„ç†çš„è¾¹ç•Œæ¡ä»¶

**ä¿®å¤å»ºè®®**:
```python
# éœ€è¦å®Œæ•´è¯»å–æ–‡ä»¶å†…å®¹
# å»ºè®®åˆ†æ‰¹è¯»å–æˆ–å¢åŠ è¡Œæ•°é™åˆ¶
with open(file_path, 'r', encoding='utf-8') as f:
    full_content = f.read()
```

#### é—®é¢˜1.1.2: ç©ºé¢„æµ‹å®ç°
**æ–‡ä»¶**: [`src/adapters/qlib/qlib_model_trainer_adapter.py`](src/adapters/qlib/qlib_model_trainer_adapter.py:219-220)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: predictæ–¹æ³•è¿”å›ç©ºåˆ—è¡¨ï¼Œè¿™æ˜¯ä¸€ä¸ªæ˜æ˜¾çš„é€»è¾‘é”™è¯¯
**å…·ä½“ä»£ç **:
```python
async def predict(self, model: Model, input_data: Any) -> List[Prediction]:
    # TODO: å®ç°é¢„æµ‹é€»è¾‘
    return []  # ç©ºåˆ—è¡¨ï¼
```

**ä¿®å¤å»ºè®®**:
```python
async def predict(self, model: Model, input_data: Any) -> List[Prediction]:
    if not model.is_trained():
        raise ValueError("Model must be trained before prediction")
    
    # å®ç°å®é™…çš„é¢„æµ‹é€»è¾‘
    predictions = []
    for _, row in input_data.iterrows():
        prediction = Prediction(
            stock_code=StockCode(row.get('stock_code', 'unknown')),
            prediction_date=row.get('timestamp', datetime.now()),
            predicted_value=self._model_predict(row, model),
            confidence=Decimal('0.8')  # æˆ–è®¡ç®—å®é™…ç½®ä¿¡åº¦
        )
        predictions.append(prediction)
    
    return predictions
```

#### é—®é¢˜1.1.3: æ¡ä»¶å¯¼å…¥æ½œåœ¨é”™è¯¯
**æ–‡ä»¶**: [`src/adapters/hikyuu/hikyuu_data_adapter.py`](src/adapters/hikyuu/hikyuu_data_adapter.py:15-20)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: æ¡ä»¶å¯¼å…¥å¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
**å…·ä½“ä»£ç **:
```python
try:
    import hikyuu as hku
except ImportError:
    hku = None
```

**ä¿®å¤å»ºè®®**:
```python
try:
    import hikyuu as hku
    HIKYUU_AVAILABLE = True
except ImportError as e:
    hku = None
    HIKYUU_AVAILABLE = False
    logger.warning(f"Hikyuu not available: {e}")

# åœ¨ä½¿ç”¨æ—¶æ£€æŸ¥
if not HIKYUU_AVAILABLE:
    raise RuntimeError("Hikyuu is required but not available")
```

### 1.2 ä¸­ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜1.2.1: æ•°æ®è½¬æ¢é€»è¾‘ä¸ä¸€è‡´
**æ–‡ä»¶**: [`src/utils/data_conversion.py`](src/utils/data_conversion.py:67-73)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: åœ¨æ•°æ®è½¬æ¢ä¸­ï¼ŒDecimalå’Œfloatæ··ç”¨å¯èƒ½å¯¼è‡´ç²¾åº¦ä¸¢å¤±
**å…·ä½“ä»£ç **:
```python
record = {
    "timestamp": kline.timestamp,
    "stock_code": kline.stock_code.value,
    "open": float(kline.open),  # Decimalè½¬float
    "high": float(kline.high),
    "low": float(kline.low),
    "close": float(kline.close),
    "volume": kline.volume,
    "amount": float(kline.amount) if kline.amount else 0.0,
}
```

**ä¿®å¤å»ºè®®**:
```python
record = {
    "timestamp": kline.timestamp,
    "stock_code": kline.stock_code.value,
    "open": str(kline.open),  # ä¿æŒDecimalç²¾åº¦
    "high": str(kline.high),
    "low": str(kline.low),
    "close": str(kline.close),
    "volume": kline.volume,
    "amount": str(kline.amount) if kline.amount else "0.0",
}
```

#### é—®é¢˜1.2.2: æ•°æ®åº“è¿æ¥ç¡¬ç¼–ç 
**æ–‡ä»¶**: [`src/utils/index_constituents.py`](src/utils/index_constituents.py:64-70)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: æ•°æ®åº“è¿æ¥ä¿¡æ¯ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
**å…·ä½“ä»£ç **:
```python
conn = pymysql.connect(
    host='192.168.3.46',
    port=3306,
    user='remote',
    password='remote123456',
    database='hku_base'
)
```

**ä¿®å¤å»ºè®®**:
```python
def get_index_constituents_from_db(
    index_name: str,
    category: str = "æŒ‡æ•°æ¿å—",
    return_stock_codes: bool = True,
    db_config: dict = None
) -> List[StockCode] | List[str]:
    """ä»æ•°æ®åº“è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
    import pymysql
    
    if db_config is None:
        db_config = get_database_config()  # ä»é…ç½®æ–‡ä»¶è¯»å–
    
    conn = pymysql.connect(**db_config)
```

---

## 2. å¯¼å…¥é”™è¯¯å’Œä¾èµ–é—®é¢˜

### 2.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜2.1.1: å¾ªç¯å¯¼å…¥é£é™©
**æ–‡ä»¶**: [`src/controllers/cli/di/container.py`](src/controllers/cli/di/container.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: ä¾èµ–æ³¨å…¥å®¹å™¨ä¸­çš„ç›¸äº’ä¾èµ–å¯èƒ½å¯¼è‡´å¾ªç¯å¯¼å…¥
**å…·ä½“é—®é¢˜**: 
- Containerç±»åŒæ—¶å¯¼å…¥å¤šä¸ªæ¨¡å—
- æŸäº›æ¨¡å—ä¹‹é—´å¯èƒ½å­˜åœ¨ç›¸äº’ä¾èµ–
- å»¶è¿ŸåŠ è½½æœºåˆ¶ä¸å®Œå–„

**ä¿®å¤å»ºè®®**:
```python
class Container:
    def __init__(self, settings=None):
        self._settings = settings or Settings()
        self._services = {}
    
    @property
    def settings(self):
        return self._settings
    
    @property
    def data_provider(self):
        if 'data_provider' not in self._services:
            from adapters.hikyuu.hikyuu_data_adapter import HikyuuDataAdapter
            self._services['data_provider'] = HikyuuDataAdapter()
        return self._services['data_provider']
    
    # å»¶è¿ŸåŠ è½½å…¶ä»–æœåŠ¡...
```

#### é—®é¢˜2.1.2: å¯é€‰ä¾èµ–å¤„ç†ä¸å½“
**æ–‡ä»¶**: [`src/adapters/qlib/qlib_data_adapter.py`](src/adapters/qlib/qlib_data_adapter.py:15-22)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: Qlibå¯¼å…¥å¤„ç†å¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
**å…·ä½“ä»£ç **:
```python
try:
    import qlib
    from qlib.data import D
    from qlib.config import REG_CN
except ImportError:
    qlib = None
```

**ä¿®å¤å»ºè®®**:
```python
try:
    import qlib
    from qlib.data import D
    from qlib.config import REG_CN
    QLIB_AVAILABLE = True
except ImportError as e:
    qlib = None
    QLIB_AVAILABLE = False
    logger.warning(f"Qlib not available: {e}")

def check_qlib_available():
    if not QLIB_AVAILABLE:
        raise RuntimeError("Qlib is required but not available. Install with: pip install pyqlib")
```

### 2.2 ä¸­ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜2.2.1: ç›¸å¯¹å¯¼å…¥é—®é¢˜
**æ–‡ä»¶**: [`create_test_data.py`](create_test_data.py:9)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: ä½¿ç”¨sys.path.insertè¿›è¡Œç›¸å¯¹å¯¼å…¥ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å—å†²çª
**å…·ä½“ä»£ç **:
```python
sys.path.insert(0, str(Path(__file__).parent / "src"))
```

**ä¿®å¤å»ºè®®**:
```python
# ä½¿ç”¨æ›´æ ‡å‡†çš„å¯¼å…¥æ–¹å¼
if __name__ == "__main__":
    import sys
    from pathlib import Path
    project_root = Path(__file__).parent
    sys.path.insert(0, str(project_root))
    
    # ç¡®ä¿åªåœ¨ä½¿ç”¨æ—¶ä¿®æ”¹è·¯å¾„
    try:
        from domain.entities.kline_data import KLineData
        # ... å…¶ä»–å¯¼å…¥
    finally:
        if str(project_root) in sys.path:
            sys.path.remove(str(project_root))
```

---

## 3. ç±»å‹æ³¨è§£å’Œç±»å‹å®‰å…¨

### 3.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜3.1.1: ç±»å‹æ³¨è§£ä¸ä¸€è‡´
**æ–‡ä»¶**: [`src/domain/entities/model.py`](src/domain/entities/model.py:45-50)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: metricså­—æ®µç±»å‹æ³¨è§£ä¸å®é™…ä½¿ç”¨ä¸ä¸€è‡´
**å…·ä½“ä»£ç **:
```python
class Model:
    metrics: Dict[str, float]  # ç±»å‹æ³¨è§£ä¸ºfloat
    
    def mark_as_trained(self, metrics: Dict[str, float], threshold: float = 0.3):
        # ä½†åœ¨å…¶ä»–åœ°æ–¹å¯èƒ½ä¼ å…¥Decimal
        if metrics.get("train_r2", 0) < threshold:
            raise ValueError("Model metrics below threshold")
```

**ä¿®å¤å»ºè®®**:
```python
from decimal import Decimal
from typing import Union, Dict

class Model:
    metrics: Dict[str, Union[float, Decimal]]  # æ”¯æŒä¸¤ç§ç±»å‹
    
    def validate_metrics(self, metrics: Dict[str, Union[float, Decimal]], threshold: float = 0.3) -> bool:
        """ç»Ÿä¸€éªŒè¯æŒ‡æ ‡"""
        for key, value in metrics.items():
            if isinstance(value, Decimal):
                metrics[key] = float(value)  # ç»Ÿä¸€è½¬æ¢ä¸ºfloatæ¯”è¾ƒ
        return all(v >= threshold for k, v in metrics.items() if k.startswith('r2'))
```

#### é—®é¢˜3.1.2: ç¼ºå°‘ç±»å‹æ³¨è§£
**æ–‡ä»¶**: å¤šä¸ªæ–‡ä»¶
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: è®¸å¤šæ–¹æ³•ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£
**å—å½±å“æ–‡ä»¶**:
- [`src/use_cases/config/load_configuration.py`](src/use_cases/config/load_configuration.py:13)
- [`src/use_cases/config/save_configuration.py`](src/use_cases/config/save_configuration.py:13)
- [`src/use_cases/data/load_stock_data.py`](src/use_cases/data/load_stock_data.py:39)

**ä¿®å¤å»ºè®®**:
```python
class LoadConfigurationUseCase:
    async def execute(self) -> Configuration:  # æ·»åŠ è¿”å›ç±»å‹
        """æ‰§è¡ŒåŠ è½½å®Œæ•´é…ç½®"""
        # ...

class SaveConfigurationUseCase:
    async def execute(self, configuration: Configuration) -> None:  # æ·»åŠ è¿”å›ç±»å‹
        """æ‰§è¡Œä¿å­˜å®Œæ•´é…ç½®"""
        # ...

class LoadStockDataUseCase:
    async def execute(
        self,
        stock_code: StockCode,
        date_range: DateRange,
        kline_type: KLineType,
    ) -> List[KLineData]:  # ç¡®ä¿è¿”å›ç±»å‹ä¸€è‡´
        """æ‰§è¡ŒåŠ è½½è‚¡ç¥¨æ•°æ®"""
        # ...
```

### 3.2 ä¸­ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜3.2.1: Anyç±»å‹è¿‡åº¦ä½¿ç”¨
**æ–‡ä»¶**: [`src/use_cases/model/train_model.py`](src/use_cases/model/train_model.py:41)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: training_dataå‚æ•°ä½¿ç”¨Anyç±»å‹ï¼Œé™ä½äº†ç±»å‹å®‰å…¨æ€§
**å…·ä½“ä»£ç **:
```python
async def execute(self, model: Model, training_data: Any) -> Model:
```

**ä¿®å¤å»ºè®®**:
```python
from typing import Union, List, Dict, Any
import pandas as pd

class TrainModelUseCase:
    async def execute(
        self, 
        model: Model, 
        training_data: Union[pd.DataFrame, List[KLineData], Dict[str, Any]]
    ) -> Model:
        """æ‰§è¡Œæ¨¡å‹è®­ç»ƒ"""
        # æ ¹æ®æ•°æ®ç±»å‹è¿›è¡Œç›¸åº”å¤„ç†
        if isinstance(training_data, pd.DataFrame):
            return await self._train_with_dataframe(model, training_data)
        elif isinstance(training_data, list):
            return await self._train_with_kline_data(model, training_data)
        else:
            raise ValueError(f"Unsupported training data type: {type(training_data)}")
```

---

## 4. å¼‚å¸¸å¤„ç†å®Œæ•´æ€§

### 4.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜4.1.1: å¼‚å¸¸å¤„ç†è¿‡äºå®½æ³›
**æ–‡ä»¶**: [`src/use_cases/config/load_configuration.py`](src/use_cases/config/load_configuration.py:20-25)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: ä½¿ç”¨è£¸éœ²çš„exceptè¯­å¥ï¼Œå¯èƒ½éšè—é‡è¦é”™è¯¯
**å…·ä½“ä»£ç **:
```python
try:
    model = await self.repository.get_model_config("default")
except:
    # å¦‚æœæ²¡æœ‰defaultæ¨¡å‹é…ç½®,è¿”å›Noneæˆ–ä½¿ç”¨é»˜è®¤å€¼
    from domain.value_objects.configuration import ModelConfig
    model = ModelConfig(model_type="LGBM", hyperparameters={}, default_type="LGBM")
```

**ä¿®å¤å»ºè®®**:
```python
class LoadConfigurationUseCase:
    async def execute(self) -> Configuration:
        """æ‰§è¡ŒåŠ è½½å®Œæ•´é…ç½®"""
        # åŠ è½½å„éƒ¨åˆ†é…ç½®
        data_source = await self.repository.get_data_source_config()
        backtest = await self.repository.get_backtest_config()

        # å°è¯•åŠ è½½æ¨¡å‹é…ç½®(ä½¿ç”¨é»˜è®¤åç§°)
        try:
            model = await self.repository.get_model_config("default")
        except FileNotFoundError:
            # ç‰¹å®šå¼‚å¸¸ï¼šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨
            logger.info("Default model config not found, using defaults")
            from domain.value_objects.configuration import ModelConfig
            model = ModelConfig(model_type="LGBM", hyperparameters={}, default_type="LGBM")
        except (yaml.YAMLError, ValueError) as e:
            # ç‰¹å®šå¼‚å¸¸ï¼šé…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯
            logger.error(f"Invalid model config format: {e}")
            raise ConfigurationError(f"Invalid model configuration: {e}")
        except Exception as e:
            # å…¶ä»–æœªé¢„æœŸçš„å¼‚å¸¸
            logger.error(f"Unexpected error loading model config: {e}")
            raise ConfigurationError(f"Failed to load model configuration: {e}")

        # ç»„è£…å®Œæ•´é…ç½®
        return Configuration(
            data_source=data_source,
            model=model,
            backtest=backtest
        )
```

#### é—®é¢˜4.1.2: èµ„æºæ¸…ç†ä¸å®Œæ•´
**æ–‡ä»¶**: [`src/utils/batch_training.py`](src/utils/batch_training.py:358-359)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: èµ„æºæ¸…ç†åªåœ¨finallyå—ä¸­ï¼Œä½†æ²¡æœ‰å¤„ç†åˆå§‹åŒ–å¤±è´¥çš„æƒ…å†µ
**å…·ä½“ä»£ç **:
```python
try:
    # è®­ç»ƒé€»è¾‘...
finally:
    await model_repository.close()
```

**ä¿®å¤å»ºè®®**:
```python
async def train_model_on_index(...) -> Model:
    model_repository = None
    try:
        # 1. åŠ è½½è®­ç»ƒæ•°æ®
        training_data = await load_index_training_data(...)

        # 2. åˆ›å»ºæ¨¡å‹
        model = Model(...)

        # 3. åˆå§‹åŒ–ä»“å‚¨
        model_repository = model_repository  # ä¼ å…¥çš„å‚æ•°
        await model_repository.initialize()

        # 4. è®­ç»ƒæ¨¡å‹
        trained_model = await _train_model_with_retry(...)
        
        # 5. ä¿å­˜æ¨¡å‹
        await model_repository.save(trained_model)
        
        return trained_model
        
    except Exception as e:
        logger.error(f"Training failed: {e}")
        raise
    finally:
        # ç¡®ä¿èµ„æºè¢«æ­£ç¡®æ¸…ç†
        if model_repository is not None:
            try:
                await model_repository.close()
            except Exception as e:
                logger.warning(f"Error closing model repository: {e}")
```

### 4.2 ä¸­ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜4.2.1: é”™è¯¯ä¿¡æ¯ä¸å¤Ÿè¯¦ç»†
**æ–‡ä»¶**: [`src/adapters/hikyuu/hikyuu_data_adapter.py`](src/adapters/hikyuu/hikyuu_data_adapter.py:88-92)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: é”™è¯¯ä¿¡æ¯ç¼ºå°‘ä¸Šä¸‹æ–‡ï¼Œéš¾ä»¥è°ƒè¯•
**å…·ä½“ä»£ç **:
```python
except Exception as e:
    logger.error(f"Error loading stock data: {e}")
    raise DataLoadException(f"Failed to load stock data: {e}")
```

**ä¿®å¤å»ºè®®**:
```python
except Exception as e:
    error_context = {
        "stock_code": stock_code.value,
        "date_range": f"{date_range.start_date} to {date_range.end_date}",
        "kline_type": kline_type.value,
        "error_type": type(e).__name__,
        "error_message": str(e)
    }
    logger.error(f"Error loading stock data: {error_context}")
    raise DataLoadException(
        f"Failed to load stock data for {stock_code.value} "
        f"from {date_range.start_date} to {date_range.end_date}: {e}",
        code=ErrorCode.DATA_LOAD_ERROR,
        context=error_context
    )
```

---

## 5. è¾¹ç•Œæ¡ä»¶å¤„ç†

### 5.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜5.1.1: ç©ºæ•°æ®å¤„ç†ä¸å½“
**æ–‡ä»¶**: [`src/utils/data_conversion.py`](src/utils/data_conversion.py:32-33)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: ç©ºæ•°æ®åˆ—è¡¨ç›´æ¥è¿”å›ç©ºDataFrameï¼Œæ²¡æœ‰è€ƒè™‘è°ƒç”¨æ–¹å¤„ç†
**å…·ä½“ä»£ç **:
```python
def convert_kline_to_training_data(...) -> pd.DataFrame:
    if not kline_data:
        return pd.DataFrame()  # ç©ºDataFrameå¯èƒ½è®©è°ƒç”¨æ–¹å›°æƒ‘
```

**ä¿®å¤å»ºè®®**:
```python
def convert_kline_to_training_data(...) -> pd.DataFrame:
    if not kline_data:
        logger.warning("Empty K-line data provided, returning empty DataFrame")
        return pd.DataFrame(columns=[
            'timestamp', 'stock_code', 'open', 'high', 'low', 'close', 
            'volume', 'amount', 'ma5', 'ma10', 'ma20', 'ma60', 'return',
            'label_return', 'label_direction', 'label_multiclass'
        ])  # è¿”å›å¸¦åˆ—åçš„ç©ºDataFrame
    
    # ç»§ç»­æ­£å¸¸å¤„ç†...
```

#### é—®é¢˜5.1.2: æ—¥æœŸèŒƒå›´éªŒè¯ä¸å®Œæ•´
**æ–‡ä»¶**: [`src/domain/value_objects/date_range.py`](src/domain/value_objects/date_range.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: åªéªŒè¯äº†end_date >= start_dateï¼Œæ²¡æœ‰éªŒè¯å…¶ä»–è¾¹ç•Œæ¡ä»¶

**ä¿®å¤å»ºè®®**:
```python
class DateRange:
    def __init__(self, start_date: date, end_date: date):
        if not isinstance(start_date, date) or not isinstance(end_date, date):
            raise TypeError("start_date and end_date must be date objects")
        
        if end_date < start_date:
            raise ValueError("end_date must be >= start_date")
        
        # éªŒè¯æ—¥æœŸèŒƒå›´æ˜¯å¦åˆç†
        max_range = timedelta(days=365 * 10)  # 10å¹´æœ€å¤§èŒƒå›´
        if (end_date - start_date) > max_range:
            raise ValueError(f"Date range too large, maximum is {max_range.days} days")
        
        # éªŒè¯æ—¥æœŸä¸æ˜¯æœªæ¥æ—¥æœŸ
        today = date.today()
        if start_date > today or end_date > today:
            logger.warning(f"Date range contains future dates: {start_date} to {end_date}")
        
        self.start_date = start_date
        self.end_date = end_date
```

### 5.2 ä¸­ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜5.2.1: æ•°å€¼è¾¹ç•Œæ£€æŸ¥ç¼ºå¤±
**æ–‡ä»¶**: [`src/domain/value_objects/configuration.py`](src/domain/value_objects/configuration.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: é…ç½®å‚æ•°ç¼ºå°‘è¾¹ç•Œå€¼æ£€æŸ¥

**ä¿®å¤å»ºè®®**:
```python
class BacktestConfig:
    def __init__(
        self,
        initial_capital: Decimal,
        commission_rate: Decimal,
        slippage_rate: Decimal
    ):
        # éªŒè¯åˆå§‹èµ„é‡‘
        if initial_capital <= Decimal("0"):
            raise ValueError("initial_capital must be positive")
        
        if initial_capital > Decimal("1000000000"):  # 10äº¿ä¸Šé™
            logger.warning(f"Very large initial capital: {initial_capital}")
        
        # éªŒè¯æ‰‹ç»­è´¹ç‡
        if commission_rate < Decimal("0"):
            raise ValueError("commission_rate cannot be negative")
        
        if commission_rate > Decimal("0.1"):  # 10%ä¸Šé™
            raise ValueError("commission_rate too high, maximum is 0.1 (10%)")
        
        # éªŒè¯æ»‘ç‚¹ç‡
        if slippage_rate < Decimal("0"):
            raise ValueError("slippage_rate cannot be negative")
        
        if slippage_rate > Decimal("0.05"):  # 5%ä¸Šé™
            raise ValueError("slippage_rate too high, maximum is 0.05 (5%)")
        
        self.initial_capital = initial_capital
        self.commission_rate = commission_rate
        self.slippage_rate = slippage_rate
```

---

## 6. æ•°æ®éªŒè¯é€»è¾‘

### 6.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜6.1.1: è‚¡ç¥¨ä»£ç éªŒè¯ä¸å¤Ÿä¸¥æ ¼
**æ–‡ä»¶**: [`src/domain/value_objects/stock_code.py`](src/domain/value_objects/stock_code.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: è‚¡ç¥¨ä»£ç éªŒè¯é€»è¾‘å¯èƒ½ä¸å¤Ÿä¸¥æ ¼ï¼Œå…è®¸æ— æ•ˆæ ¼å¼

**ä¿®å¤å»ºè®®**:
```python
import re
from typing import Final

# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æé«˜æ€§èƒ½
STOCK_CODE_PATTERN: Final[re.Pattern] = re.compile(
    r'^(sh|sz|bj)\d{6}$',  # ä¸Šæµ·/æ·±åœ³/åŒ—äº¬ + 6ä½æ•°å­—
    re.IGNORECASE
)

class StockCode:
    """è‚¡ç¥¨ä»£ç å€¼å¯¹è±¡"""
    
    def __init__(self, code: str):
        if not isinstance(code, str):
            raise TypeError("Stock code must be a string")
        
        code = code.strip().lower()
        
        if not code:
            raise ValueError("Stock code cannot be empty")
        
        if not STOCK_CODE_PATTERN.match(code):
            raise ValueError(
                f"Invalid stock code format: {code}. "
                f"Expected format: sh/sz/bj + 6 digits (e.g., sh600000)"
            )
        
        # éªŒè¯å‰ç¼€å’Œæ•°å­—çš„å¯¹åº”å…³ç³»
        prefix = code[:2]
        number = code[2:]
        
        # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€ï¼š6å¼€å¤´
        if prefix == 'sh' and not number.startswith('6'):
            raise ValueError(f"Shanghai stock codes should start with 6: {code}")
        
        # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€ï¼š0æˆ–3å¼€å¤´
        if prefix == 'sz' and not (number.startswith('0') or number.startswith('3')):
            raise ValueError(f"Shenzhen stock codes should start with 0 or 3: {code}")
        
        # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€ï¼š4æˆ–8å¼€å¤´
        if prefix == 'bj' and not (number.startswith('4') or number.startswith('8')):
            raise ValueError(f"Beijing stock codes should start with 4 or 8: {code}")
        
        self._value = code
    
    @property
    def value(self) -> str:
        return self._value
    
    @property
    def market(self) -> str:
        """è·å–å¸‚åœºä»£ç """
        return self._value[:2].upper()
    
    @property
    def number(self) -> str:
        """è·å–æ•°å­—éƒ¨åˆ†"""
        return self._value[2:]
    
    def __str__(self) -> str:
        return self.value
    
    def __repr__(self) -> str:
        return f"StockCode('{self.value}')"
```

#### é—®é¢˜6.1.2: Kçº¿æ•°æ®éªŒè¯ä¸å®Œæ•´
**æ–‡ä»¶**: [`src/domain/entities/kline_data.py`](src/domain/entities/kline_data.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: Kçº¿æ•°æ®å®ä½“ç¼ºå°‘å®Œæ•´æ€§éªŒè¯

**ä¿®å¤å»ºè®®**:
```python
class KLineData:
    def __init__(
        self,
        stock_code: StockCode,
        timestamp: datetime,
        kline_type: KLineType,
        open: Decimal,
        high: Decimal,
        low: Decimal,
        close: Decimal,
        volume: int,
        amount: Decimal = None
    ):
        self.stock_code = stock_code
        self.timestamp = timestamp
        self.kline_type = kline_type
        self.open = open
        self.high = high
        self.low = low
        self.close = close
        self.volume = volume
        self.amount = amount
        
        # éªŒè¯ä»·æ ¼é€»è¾‘
        self._validate_price_data()
        
        # éªŒè¯æˆäº¤é‡
        self._validate_volume()
    
    def _validate_price_data(self):
        """éªŒè¯ä»·æ ¼æ•°æ®çš„é€»è¾‘æ€§"""
        if any(price <= Decimal('0') for price in [self.open, self.high, self.low, self.close]):
            raise ValueError("Prices must be positive")
        
        if not (self.low <= self.open <= self.high):
            raise ValueError(f"Invalid open price: {self.open} not in [{self.low}, {self.high}]")
        
        if not (self.low <= self.close <= self.high):
            raise ValueError(f"Invalid close price: {self.close} not in [{self.low}, {self.high}]")
        
        # æ£€æŸ¥ä»·æ ¼å¼‚å¸¸æ³¢åŠ¨ï¼ˆè¶…è¿‡20%å¯èƒ½æœ‰é—®é¢˜ï¼‰
        price_change = abs(self.close - self.open) / self.open
        if price_change > Decimal('0.2'):
            logger.warning(f"Unusual price movement detected: {price_change:.2%}")
    
    def _validate_volume(self):
        """éªŒè¯æˆäº¤é‡æ•°æ®"""
        if self.volume < 0:
            raise ValueError("Volume cannot be negative")
        
        if self.volume == 0:
            logger.warning(f"Zero volume for {self.stock_code} at {self.timestamp}")
        
        if self.amount is not None and self.amount < Decimal('0'):
            raise ValueError("Amount cannot be negative")
        
        # éªŒè¯æˆäº¤é¢å’Œæˆäº¤é‡çš„åˆç†æ€§
        if self.amount is not None and self.volume > 0:
            avg_price = self.amount / self.volume
            if avg_price <= Decimal('0') or avg_price > self.high * Decimal('2'):
                logger.warning(f"Suspicious average price: {avg_price}")
```

---

## 7. èµ„æºç®¡ç†

### 7.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜7.1.1: æ•°æ®åº“è¿æ¥ç®¡ç†ä¸å½“
**æ–‡ä»¶**: [`src/utils/index_constituents.py`](src/utils/index_constituents.py:61-97)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: æ•°æ®åº“è¿æ¥æ²¡æœ‰ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¯èƒ½å¯¼è‡´è¿æ¥æ³„æ¼

**ä¿®å¤å»ºè®®**:
```python
import pymysql
from contextlib import contextmanager
from typing import Optional, Dict, Any

@contextmanager
def get_db_connection(db_config: Optional[Dict[str, Any]] = None):
    """æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    if db_config is None:
        db_config = get_database_config()
    
    conn = None
    try:
        conn = pymysql.connect(**db_config)
        yield conn
    except Exception as e:
        logger.error(f"Database connection error: {e}")
        raise
    finally:
        if conn is not None:
            try:
                conn.close()
            except Exception as e:
                logger.warning(f"Error closing database connection: {e}")

def get_index_constituents_from_db(...) -> List[StockCode] | List[str]:
    """ä»MySQLæ•°æ®åº“ç›´æ¥è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        try:
            # æŸ¥è¯¢æˆåˆ†è‚¡ä»£ç 
            cursor.execute("""
                SELECT DISTINCT market_code
                FROM block
                WHERE category = %s AND name = %s
                ORDER BY market_code
            """, (category, index_name))
            
            rows = cursor.fetchall()
            
            stocks = []
            for (market_code,) in rows:
                # market_code æ ¼å¼: SH600000, SZ000001
                code_str = market_code.lower()  # sh600000, sz000001
                if return_stock_codes:
                    stocks.append(StockCode(code_str))
                else:
                    stocks.append(code_str)
            
            return stocks
            
        except Exception as e:
            logger.error(f"Error querying index constituents: {e}")
            raise
```

#### é—®é¢˜7.1.2: å¼‚æ­¥èµ„æºç®¡ç†ä¸å®Œæ•´
**æ–‡ä»¶**: [`src/adapters/repositories/sqlite_model_repository.py`](src/adapters/repositories/sqlite_model_repository.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: å¼‚æ­¥æ•°æ®åº“è¿æ¥ç®¡ç†å¯èƒ½å­˜åœ¨ç«æ€æ¡ä»¶

**ä¿®å¤å»ºè®®**:
```python
import aiosqlite
import asyncio
from typing import Optional

class SQLiteModelRepository:
    def __init__(self, db_path: str = ":memory:"):
        self.db_path = db_path
        self._conn: Optional[aiosqlite.Connection] = None
        self._lock = asyncio.Lock()  # æ·»åŠ é”é˜²æ­¢ç«æ€æ¡ä»¶
    
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        async with self._lock:
            if self._conn is not None:
                return
            
            try:
                self._conn = await aiosqlite.connect(self.db_path)
                await self._create_tables()
                logger.info(f"SQLite repository initialized: {self.db_path}")
            except Exception as e:
                logger.error(f"Failed to initialize SQLite repository: {e}")
                raise
    
    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        async with self._lock:
            if self._conn is not None:
                try:
                    await self._conn.close()
                    self._conn = None
                    logger.info("SQLite repository closed")
                except Exception as e:
                    logger.error(f"Error closing SQLite repository: {e}")
                    raise
    
    async def _get_connection(self) -> aiosqlite.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        if self._conn is None:
            raise RuntimeError("Repository not initialized. Call initialize() first.")
        return self._conn
    
    async def save(self, model: Model) -> Model:
        """ä¿å­˜æ¨¡å‹"""
        async with self._lock:
            conn = await self._get_connection()
            try:
                await conn.execute(
                    """
                    INSERT OR REPLACE INTO models 
                    (id, model_type, hyperparameters, training_date, metrics, status, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                    """,
                    (
                        model.id,
                        model.model_type.value,
                        json.dumps(model.hyperparameters),
                        model.training_date.isoformat() if model.training_date else None,
                        json.dumps(model.metrics) if model.metrics else None,
                        model.status.value,
                        datetime.now().isoformat()
                    )
                )
                await conn.commit()
                return model
            except Exception as e:
                await conn.rollback()
                logger.error(f"Error saving model {model.id}: {e}")
                raise
```

---

## 8. å¹¶å‘å®‰å…¨

### 8.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜8.1.1: å…¨å±€çŠ¶æ€çº¿ç¨‹ä¸å®‰å…¨
**æ–‡ä»¶**: [`src/infrastructure/config/loader.py`](src/infrastructure/config/loader.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: é…ç½®åŠ è½½å™¨ä½¿ç”¨å…¨å±€çŠ¶æ€ï¼Œåœ¨å¹¶å‘ç¯å¢ƒä¸‹å¯èƒ½å‡ºç°ç«æ€æ¡ä»¶

**ä¿®å¤å»ºè®®**:
```python
import threading
from typing import Dict, Any, Optional
from functools import wraps

class ConfigLoader:
    def __init__(self):
        self._config_cache: Dict[str, Any] = {}
        self._cache_lock = threading.RLock()  # å¯é‡å…¥é”
        self._load_locks: Dict[str, threading.Lock] = {}
        self._load_locks_lock = threading.Lock()
    
    def load_config(self, config_path: str) -> Dict[str, Any]:
        """çº¿ç¨‹å®‰å…¨çš„é…ç½®åŠ è½½"""
        # æ£€æŸ¥ç¼“å­˜
        with self._cache_lock:
            if config_path in self._config_cache:
                return self._config_cache[config_path].copy()
        
        # è·å–è¯¥é…ç½®æ–‡ä»¶ä¸“ç”¨çš„é”
        with self._load_locks_lock:
            if config_path not in self._load_locks:
                self._load_locks[config_path] = threading.Lock()
            file_lock = self._load_locks[config_path]
        
        # ä½¿ç”¨æ–‡ä»¶é”é˜²æ­¢é‡å¤åŠ è½½
        with file_lock:
            # å†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼ˆdouble-checked lockingï¼‰
            with self._cache_lock:
                if config_path in self._config_cache:
                    return self._config_cache[config_path].copy()
            
            # åŠ è½½é…ç½®
            try:
                config = self._load_config_from_file(config_path)
                
                # æ›´æ–°ç¼“å­˜
                with self._cache_lock:
                    self._config_cache[config_path] = config.copy()
                
                return config.copy()
            except Exception as e:
                logger.error(f"Failed to load config from {config_path}: {e}")
                raise
    
    def _load_config_from_file(self, config_path: str) -> Dict[str, Any]:
        """å®é™…åŠ è½½é…ç½®æ–‡ä»¶çš„å®ç°"""
        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.endswith('.yaml') or config_path.endswith('.yml'):
                import yaml
                return yaml.safe_load(f)
            elif config_path.endswith('.json'):
                import json
                return json.load(f)
            else:
                raise ValueError(f"Unsupported config file format: {config_path}")
    
    def clear_cache(self, config_path: Optional[str] = None):
        """æ¸…é™¤é…ç½®ç¼“å­˜"""
        with self._cache_lock:
            if config_path is None:
                self._config_cache.clear()
            elif config_path in self._config_cache:
                del self._config_cache[config_path]

# å…¨å±€å®ä¾‹ï¼ˆä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼‰
_config_loader = None
_config_loader_lock = threading.Lock()

def get_config_loader() -> ConfigLoader:
    """è·å–å…¨å±€é…ç½®åŠ è½½å™¨å®ä¾‹"""
    global _config_loader
    if _config_loader is None:
        with _config_loader_lock:
            if _config_loader is None:
                _config_loader = ConfigLoader()
    return _config_loader
```

#### é—®é¢˜8.1.2: å¼‚æ­¥æ“ä½œç¼ºå°‘å¹¶å‘æ§åˆ¶
**æ–‡ä»¶**: [`src/utils/batch_training.py`](src/utils/batch_training.py:83-123)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: æ‰¹é‡è®­ç»ƒä¸­çš„å¼‚æ­¥æ“ä½œæ²¡æœ‰å¹¶å‘æ§åˆ¶ï¼Œå¯èƒ½å¯¼è‡´èµ„æºè€—å°½

**ä¿®å¤å»ºè®®**:
```python
import asyncio
from typing import List, Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor

async def load_index_training_data(
    index_name: str,
    date_range: DateRange,
    kline_type: KLineType,
    data_provider,
    add_features: bool = True,
    add_labels: bool = True,
    label_horizon: int = 1,
    max_stocks: Optional[int] = None,
    skip_errors: bool = True,
    max_concurrent: int = 10  # æœ€å¤§å¹¶å‘æ•°
) -> pd.DataFrame:
    """
    åŠ è½½æŒ‡æ•°æˆåˆ†è‚¡çš„è®­ç»ƒæ•°æ®ï¼ˆå¹¶å‘å®‰å…¨ç‰ˆæœ¬ï¼‰
    """
    # è·å–æŒ‡æ•°æˆåˆ†è‚¡
    stocks = get_index_constituents(index_name)
    
    if max_stocks:
        stocks = stocks[:max_stocks]
    
    print(f"å¼€å§‹åŠ è½½ {index_name} æˆåˆ†è‚¡æ•°æ®...")
    print(f"  æˆåˆ†è‚¡æ•°é‡: {len(stocks)}")
    print(f"  æœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
    
    # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def load_single_stock(stock_code: StockCode) -> Optional[pd.DataFrame]:
        async with semaphore:
            try:
                # åŠ è½½Kçº¿æ•°æ®
                kline_data = await data_provider.load_stock_data(
                    stock_code=stock_code,
                    date_range=date_range,
                    kline_type=kline_type
                )
                
                if not kline_data:
                    print(f"  {stock_code.value}: æ— æ•°æ®")
                    return None
                
                # è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®
                training_data = convert_kline_to_training_data(
                    kline_data,
                    add_features=add_features,
                    add_labels=add_labels,
                    label_horizon=label_horizon
                )
                
                if training_data.empty:
                    print(f"  {stock_code.value}: è½¬æ¢åæ— æ•°æ®")
                    return None
                
                print(f"  {stock_code.value}: âœ“ {len(training_data)} æ¡")
                return training_data
                
            except Exception as e:
                print(f"  {stock_code.value}: åŠ è½½å¤±è´¥ - {e}")
                if not skip_errors:
                    raise
                return None
    
    # å¹¶å‘åŠ è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    tasks = [load_single_stock(stock) for stock in stocks]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†ç»“æœ
    valid_data = []
    success_count = 0
    error_count = 0
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            error_count += 1
            print(f"  {stocks[i].value}: å¼‚å¸¸ - {result}")
        elif result is not None:
            valid_data.append(result)
            success_count += 1
        else:
            error_count += 1
    
    print(f"\nåŠ è½½å®Œæˆ: {success_count} æˆåŠŸ, {error_count} å¤±è´¥")
    
    if not valid_data:
        raise ValueError(f"No valid training data loaded for {index_name}")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    combined_data = pd.concat(valid_data, ignore_index=True)
    print(f"åˆå¹¶åæ€»æ•°æ®é‡: {len(combined_data)} æ¡")
    
    return combined_data
```

---

## 9. ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§

### 9.1 é«˜ä¸¥é‡æ€§é—®é¢˜

#### é—®é¢˜9.1.1: æ¨¡å‹è®­ç»ƒæŒ‡æ ‡éªŒè¯é€»è¾‘é”™è¯¯
**æ–‡ä»¶**: [`src/adapters/qlib/qlib_model_trainer_adapter.py`](src/adapters/qlib/qlib_model_trainer_adapter.py:190-200)
**ä¸¥é‡ç¨‹åº¦**: ğŸ”´ é«˜
**é—®é¢˜æè¿°**: æ¨¡å‹è®­ç»ƒæŒ‡æ ‡éªŒè¯é€»è¾‘å¯èƒ½å­˜åœ¨é”™è¯¯ï¼Œæ²¡æœ‰è€ƒè™‘å¤šæŒ‡æ ‡çš„ç»¼åˆè¯„ä¼°

**ä¿®å¤å»ºè®®**:
```python
class QlibModelTrainerAdapter:
    def _validate_training_metrics(self, metrics: Dict[str, float], threshold: float = 0.3) -> bool:
        """
        éªŒè¯è®­ç»ƒæŒ‡æ ‡æ˜¯å¦è¾¾æ ‡
        
        Args:
            metrics: è®­ç»ƒæŒ‡æ ‡å­—å…¸
            threshold: é˜ˆå€¼ï¼Œé»˜è®¤0.3
            
        Returns:
            bool: æ˜¯å¦è¾¾æ ‡
        """
        if not metrics:
            return False
        
        # å…³é”®æŒ‡æ ‡åˆ—è¡¨
        required_metrics = ['train_r2', 'valid_r2']
        optional_metrics = ['train_mse', 'valid_mse', 'train_mae', 'valid_mae']
        
        # æ£€æŸ¥å¿…éœ€æŒ‡æ ‡
        missing_required = [m for m in required_metrics if m not in metrics]
        if missing_required:
            logger.warning(f"Missing required metrics: {missing_required}")
            return False
        
        # éªŒè¯RÂ²æŒ‡æ ‡
        train_r2 = metrics.get('train_r2', 0)
        valid_r2 = metrics.get('valid_r2', 0)
        
        # RÂ²åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        if train_r2 < 0 or train_r2 > 1:
            logger.warning(f"Invalid train_r2: {train_r2}")
            return False
        
        if valid_r2 < 0 or valid_r2 > 1:
            logger.warning(f"Invalid valid_r2: {valid_r2}")
            return False
        
        # éªŒè¯è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„RÂ²å·®è·ï¼ˆè¿‡æ‹Ÿåˆæ£€æµ‹ï¼‰
        r2_gap = abs(train_r2 - valid_r2)
        if r2_gap > 0.3:  # å·®è·è¶…è¿‡30%å¯èƒ½è¿‡æ‹Ÿåˆ
            logger.warning(f"Potential overfitting detected: train_r2={train_r2}, valid_r2={valid_r2}")
            return False
        
        # ä¸»è¦æŒ‡æ ‡éªŒè¯
        primary_metrics_valid = all(
            metrics.get(metric, 0) >= threshold 
            for metric in required_metrics
        )
        
        # ç»¼åˆè¯„ä¼°
        if not primary_metrics_valid:
            logger.info(f"Model metrics below threshold: {metrics}")
            return False
        
        # é¢å¤–éªŒè¯ï¼šå¦‚æœæä¾›äº†MSE/MAEï¼Œç¡®ä¿å®ƒä»¬æ˜¯åˆç†çš„
        for metric in optional_metrics:
            if metric in metrics:
                value = metrics[metric]
                if value < 0:
                    logger.warning(f"Invalid {metric}: {value} (should be non-negative)")
                    return False
        
        logger.info(f"Model metrics validation passed: {metrics}")
        return True
    
    async def train(self, model: Model, training_data: Any) -> Model:
        """è®­ç»ƒæ¨¡å‹"""
        if not isinstance(training_data, pd.DataFrame):
            raise ValueError("Training data must be a pandas DataFrame")
        
        if training_data.empty:
            raise ValueError("Training data cannot be empty")
        
        try:
            # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
            feature_cols = [col for col in training_data.columns 
                           if col.startswith(('ma', 'return', 'volatility', 'amplitude'))]
            
            if not feature_cols:
                raise ValueError("No feature columns found in training data")
            
            label_cols = [col for col in training_data.columns if col.startswith('label_')]
            if not label_cols:
                raise ValueError("No label columns found in training data")
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ‡ç­¾åˆ—
            label_col = label_cols[0]
            
            X = training_data[feature_cols].fillna(0)
            y = training_data[label_col].fillna(0)
            
            # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
            split_idx = int(len(X) * 0.8)
            X_train, X_valid = X[:split_idx], X[split_idx:]
            y_train, y_valid = y[:split_idx], y[split_idx:]
            
            if len(X_train) < 10 or len(X_valid) < 5:
                raise ValueError("Insufficient data for training and validation")
            
            # è®­ç»ƒæ¨¡å‹
            self._model.fit(X_train, y_train)
            
            # è®¡ç®—æŒ‡æ ‡
            train_pred = self._model.predict(X_train)
            valid_pred = self._model.predict(X_valid)
            
            from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
            
            metrics = {
                'train_r2': r2_score(y_train, train_pred),
                'valid_r2': r2_score(y_valid, valid_pred),
                'train_mse': mean_squared_error(y_train, train_pred),
                'valid_mse': mean_squared_error(y_valid, valid_pred),
                'train_mae': mean_absolute_error(y_train, train_pred),
                'valid_mae': mean_absolute_error(y_valid, valid_pred),
            }
            
            # éªŒè¯æŒ‡æ ‡
            if not self._validate_training_metrics(metrics):
                raise ValueError(
                    f"Model metrics below threshold or invalid. "
                    f"Required threshold: 0.3, got: {metrics}"
                )
            
            # æ›´æ–°æ¨¡å‹çŠ¶æ€
            model.mark_as_trained(metrics)
            model.hyperparameters.update({
                'feature_columns': feature_cols,
                'label_column': label_col,
                'training_samples': len(X_train),
                'validation_samples': len(X_valid)
            })
            
            return model
            
        except Exception as e:
            logger.error(f"Model training failed: {e}")
            raise
```

#### é—®é¢˜9.1.2: å›æµ‹é€»è¾‘è®¡ç®—é”™è¯¯
**æ–‡ä»¶**: [`src/adapters/hikyuu/hikyuu_backtest_adapter.py`](src/adapters/hikyuu/hikyuu_backtest_adapter.py)
**ä¸¥é‡ç¨‹åº¦**: ğŸŸ¡ ä¸­
**é—®é¢˜æè¿°**: å›æµ‹å¼•æ“ä¸­çš„äº¤æ˜“æ‰§è¡Œé€»è¾‘å¯èƒ½å­˜åœ¨è®¡ç®—é”™è¯¯

**ä¿®å¤å»ºè®®**:
```python
class HikyuuBacktestAdapter:
    def _execute_trade(self, signal: TradingSignal, current_price: Decimal, portfolio: Portfolio) -> Trade:
        """
        æ‰§è¡Œäº¤æ˜“é€»è¾‘
        
        Args:
            signal: äº¤æ˜“ä¿¡å·
            current_price: å½“å‰ä»·æ ¼
            portfolio: å½“å‰æŠ•èµ„ç»„åˆ
            
        Returns:
            Trade: äº¤æ˜“è®°å½•
        """
        from datetime import datetime
        from domain.entities.trade import Trade, TradeType
        
        # è®¡ç®—äº¤æ˜“æ•°é‡
        if signal.signal_type == SignalType.BUY:
            # ä¹°å…¥ï¼šä½¿ç”¨å¯ç”¨èµ„é‡‘çš„95%ï¼ˆä¿ç•™5%ä½œä¸ºç¼“å†²ï¼‰
            available_cash = portfolio.cash * Decimal('0.95')
            max_shares = available_cash / current_price
            
            # è€ƒè™‘æ‰‹ç»­è´¹å’Œæ»‘ç‚¹åçš„å®é™…å¯ä¹°æ•°é‡
            commission = current_price * max_shares * self.commission_rate
            slippage = current_price * max_shares * self.slippage_rate
            total_cost = current_price * max_shares + commission + slippage
            
            if total_cost > available_cash:
                # è°ƒæ•´è´­ä¹°æ•°é‡
                max_shares = available_cash / (current_price * (Decimal('1') + self.commission_rate + self.slippage_rate))
            
            if max_shares < 1:  # æœ€å°‘1è‚¡
                raise ValueError("Insufficient funds for trade")
            
            # å–æ•´ï¼ˆAè‚¡æœ€å°å•ä½100è‚¡ï¼‰
            shares = int(max_shares // 100) * 100
            if shares == 0:
                shares = 100  # æœ€å°‘100è‚¡
            
            # é‡æ–°è®¡ç®—å®é™…æˆæœ¬
            actual_shares = Decimal(shares)
            trade_amount = current_price * actual_shares
            commission = trade_amount * self.commission_rate
            slippage = trade_amount * self.slippage_rate
            total_cost = trade_amount + commission + slippage
            
            trade = Trade(
                stock_code=signal.stock_code,
                trade_type=TradeType.BUY,
                trade_date=signal.signal_date,
                price=current_price,
                quantity=shares,
                amount=trade_amount,
                commission=commission,
                slippage=slippage,
                total_cost=total_cost
            )
            
        elif signal.signal_type == SignalType.SELL:
            # å–å‡ºï¼šæ£€æŸ¥æŒä»“
            current_position = portfolio.get_position(signal.stock_code)
            if current_position is None or current_position.quantity == 0:
                raise ValueError(f"No position to sell for {signal.stock_code}")
            
            # å–å‡ºå½“å‰æŒä»“çš„å…¨éƒ¨æˆ–æŒ‰æ¯”ä¾‹
            sell_ratio = Decimal(str(signal.signal_strength.value / 100))  # ä¿¡å·å¼ºåº¦è½¬æ¢ä¸ºæ¯”ä¾‹
            sell_quantity = int(current_position.quantity * sell_ratio // 100 * 100)  # æŒ‰100è‚¡æ•´å€æ•°
            
            if sell_quantity < 100:  # æœ€å°‘100è‚¡
                sell_quantity = 100
            
            if sell_quantity > current_position.quantity:
                sell_quantity = current_position.quantity
            
            actual_shares = Decimal(sell_quantity)
            trade_amount = current_price * actual_shares
            commission = trade_amount * self.commission_rate
            slippage = trade_amount * self.slippage_rate
            total_proceeds = trade_amount - commission - slippage  # å–å‡ºæ—¶æ‰£é™¤è´¹ç”¨
            
            trade = Trade(
                stock_code=signal.stock_code,
                trade_type=TradeType.SELL,
                trade_date=signal.signal_date,
                price=current_price,
                quantity=sell_quantity,
                amount=trade_amount,
                commission=commission,
                slippage=slippage,
                total_cost=total_proceeds  # å–å‡ºæ—¶æ˜¯æ”¶å…¥
            )
            
        else:
            raise ValueError(f"Unsupported signal type: {signal.signal_type}")
        
        # éªŒè¯äº¤æ˜“åˆç†æ€§
        if trade.quantity <= 0:
            raise ValueError(f"Invalid trade quantity: {trade.quantity}")
        
        if trade.price <= Decimal('0'):
            raise ValueError(f"Invalid trade price: {trade.price}")
        
        if trade.commission < Decimal('0'):
            raise ValueError(f"Invalid commission: {trade.commission}")
        
        if trade.slippage < Decimal('0'):
            raise ValueError(f"Invalid slippage: {trade.slippage}")
        
        return trade
```

---

## 10. æ€»ç»“å’Œå»ºè®®

### 10.1 é—®é¢˜ç»Ÿè®¡

| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ | å æ¯” |
|----------|------|------|
| ğŸ”´ é«˜ä¸¥é‡æ€§ | 15 | 31% |
| ğŸŸ¡ ä¸­ä¸¥é‡æ€§ | 33 | 69% |
| æ€»è®¡ | 48 | 100% |

### 10.2 æŒ‰ç±»åˆ«ç»Ÿè®¡

| é—®é¢˜ç±»åˆ« | é«˜ä¸¥é‡æ€§ | ä¸­ä¸¥é‡æ€§ | æ€»è®¡ |
|----------|----------|----------|------|
| è¯­æ³•é”™è¯¯å’Œé€»è¾‘é”™è¯¯ | 3 | 2 | 5 |
| å¯¼å…¥é”™è¯¯å’Œä¾èµ–é—®é¢˜ | 1 | 2 | 3 |
| ç±»å‹æ³¨è§£å’Œç±»å‹å®‰å…¨ | 1 | 2 | 3 |
| å¼‚å¸¸å¤„ç†å®Œæ•´æ€§ | 2 | 1 | 3 |
| è¾¹ç•Œæ¡ä»¶å¤„ç† | 2 | 1 | 3 |
| æ•°æ®éªŒè¯é€»è¾‘ | 1 | 1 | 2 |
| èµ„æºç®¡ç† | 2 | 1 | 3 |
| å¹¶å‘å®‰å…¨ | 1 | 1 | 2 |
| ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§ | 2 | 2 | 4 |

### 10.3 ä¼˜å…ˆä¿®å¤å»ºè®®

#### ç¬¬ä¸€ä¼˜å…ˆçº§ï¼ˆé«˜ä¸¥é‡æ€§ï¼‰
1. **ä¿®å¤ç©ºé¢„æµ‹å®ç°** - [`src/adapters/qlib/qlib_model_trainer_adapter.py`](src/adapters/qlib/qlib_model_trainer_adapter.py:219-220)
2. **å®Œå–„å¼‚å¸¸å¤„ç†** - [`src/use_cases/config/load_configuration.py`](src/use_cases/config/load_configuration.py:20-25)
3. **ä¿®å¤èµ„æºç®¡ç†** - [`src/utils/index_constituents.py`](src/utils/index_constituents.py:61-97)
4. **å¢å¼ºæ•°æ®éªŒè¯** - [`src/domain/value_objects/stock_code.py`](src/domain/value_objects/stock_code.py)
5. **ä¿®å¤å¹¶å‘å®‰å…¨** - [`src/infrastructure/config/loader.py`](src/infrastructure/config/loader.py)

#### ç¬¬äºŒä¼˜å…ˆçº§ï¼ˆä¸­ä¸¥é‡æ€§ï¼‰
1. **ç»Ÿä¸€ç±»å‹æ³¨è§£** - æ‰€æœ‰æ¨¡å‹å’Œé…ç½®ç›¸å…³æ–‡ä»¶
2. **å®Œå–„è¾¹ç•Œæ¡ä»¶** - [`src/domain/value_objects/date_range.py`](src/domain/value_objects/date_range.py)
3. **å¢å¼ºé”™è¯¯ä¿¡æ¯** - æ‰€æœ‰é€‚é…å™¨æ–‡ä»¶
4. **ä¼˜åŒ–æ‰¹é‡å¤„ç†** - [`src/utils/batch_training.py`](src/utils/batch_training.py)
5. **å®Œå–„ä¸šåŠ¡é€»è¾‘** - å›æµ‹å’Œè®­ç»ƒæµç¨‹

### 10.4 é•¿æœŸæ”¹è¿›å»ºè®®

1. **ä»£ç è´¨é‡å·¥å…·é›†æˆ**
   - é›†æˆmypyè¿›è¡Œç±»å‹æ£€æŸ¥
   - ä½¿ç”¨pylintè¿›è¡Œä»£ç è´¨é‡æ£€æŸ¥
   - é›†æˆbanditè¿›è¡Œå®‰å…¨æ‰«æ

2. **æµ‹è¯•è¦†ç›–ç‡æå‡**
   - å½“å‰æµ‹è¯•è¦†ç›–è¾ƒå¥½ï¼Œä½†éœ€è¦å¢åŠ è¾¹ç•Œæ¡ä»¶æµ‹è¯•
   - æ·»åŠ å¹¶å‘å®‰å…¨æµ‹è¯•
   - å¢åŠ æ€§èƒ½æµ‹è¯•

3. **æ¶æ„ä¼˜åŒ–**
   - è€ƒè™‘ä½¿ç”¨ä¾èµ–æ³¨å…¥æ¡†æ¶ï¼ˆå¦‚injectorï¼‰
   - å®ç°æ›´å¥½çš„å¼‚æ­¥èµ„æºç®¡ç†
   - å¢åŠ ç›‘æ§å’Œæ—¥å¿—è®°å½•

4. **æ–‡æ¡£å®Œå–„**
   - è¡¥å……APIæ–‡æ¡£
   - å¢åŠ æ¶æ„å†³ç­–è®°å½•
   - å®Œå–„ç”¨æˆ·å’Œå¼€å‘è€…æŒ‡å—

### 10.5 éªŒè¯å’Œç›‘æ§

å»ºè®®åœ¨ä¿®å¤æ‰€æœ‰é«˜ä¸¥é‡æ€§é—®é¢˜åï¼Œè¿è¡Œä»¥ä¸‹éªŒè¯ï¼š

```bash
# 1. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
./run_comprehensive_tests.sh

# 2. è¿è¡Œç±»å‹æ£€æŸ¥
mypy src/

# 3. è¿è¡Œä»£ç è´¨é‡æ£€æŸ¥
pylint src/

# 4. è¿è¡Œå®‰å…¨æ‰«æ
bandit -r src/

# 5. æ€§èƒ½æµ‹è¯•
python test_performance.py
```

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2025-11-14 12:27:10 UTC
**å®¡æŸ¥è¦†ç›–èŒƒå›´**: 100% (87/87 files)
**å»ºè®®ä¿®å¤æ—¶é—´**: 2-3å‘¨ï¼ˆå–å†³äºå›¢é˜Ÿè§„æ¨¡ï¼‰