# å‰©ä½™ä»»åŠ¡æ¸…å•

**åˆ›å»ºæ—¥æœŸ**: 2025-11-14
**çŠ¶æ€**: ğŸŸ¡ P1/P2ä¼˜åŒ–ä»»åŠ¡
**ä¼˜å…ˆçº§**: ä¸­ç­‰(ä¸é˜»å¡MVPå‘å¸ƒ)

---

## æ‰§è¡Œæ¦‚è¦

åŸºäºä»£ç å®¡æŸ¥,è¯†åˆ«å‡º**5ä¸ªæœªå®Œå…¨å®ç°çš„åŠŸèƒ½**ã€‚è¿™äº›åŠŸèƒ½ä¸å½±å“æ ¸å¿ƒå·¥ä½œæµ,ä½†éœ€è¦åœ¨P1é˜¶æ®µå®Œå–„ä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚

**å®Œæˆåº¦è¯„ä¼°**:
- âœ… **æ ¸å¿ƒåŠŸèƒ½**: 100% (æ•°æ®åŠ è½½ã€è®­ç»ƒã€é¢„æµ‹ã€ä¿¡å·è½¬æ¢ã€å›æµ‹)
- ğŸŸ¡ **CLIè¾…åŠ©å‘½ä»¤**: 40% (éƒ¨åˆ†å‘½ä»¤ä»…å ä½)
- ğŸŸ¡ **é«˜çº§ç‰¹æ€§**: 0% (ç¼“å­˜ã€æ‰¹é‡æ“ä½œ)

---

## ä»»åŠ¡åˆ—è¡¨

### ä»»åŠ¡1: `data list` å‘½ä»¤å®ç° ğŸŸ¡ P2

**ä½ç½®**: [src/controllers/cli/commands/data.py:205](../src/controllers/cli/commands/data.py#L205)

**å½“å‰çŠ¶æ€**:
```python
@data_group.command(name="list")
@click.pass_context
def data_list(ctx):
    """åˆ—å‡ºå·²æœ‰æ•°æ®"""
    # TODO: å®ç°åˆ—å‡ºå·²æœ‰æ•°æ®çš„é€»è¾‘
    click.echo("âœ… åˆ—å‡ºå·²æœ‰æ•°æ®åŠŸèƒ½å°šæœªå®ç°")
```

**é—®é¢˜æè¿°**:
- å‘½ä»¤åªè¿”å›å ä½æç¤º,æ— å®é™…åŠŸèƒ½
- ç”¨æˆ·æ— æ³•æŸ¥çœ‹å·²åŠ è½½çš„è‚¡ç¥¨ã€æ—¶é—´èŒƒå›´æˆ–ç¼“å­˜æ–‡ä»¶

**å½±å“èŒƒå›´**: ğŸŸ¢ **ä½**
- ä¸å½±å“æ ¸å¿ƒå·¥ä½œæµ
- ç”¨æˆ·å¯é€šè¿‡æ–‡ä»¶ç®¡ç†å™¨æŸ¥çœ‹è¾“å‡ºç›®å½•

**å»ºè®®å®ç°** (é¢„è®¡30åˆ†é’Ÿ):

```python
@data_group.command(name="list")
@click.option('--format', type=click.Choice(['table', 'json', 'csv']), default='table', help='è¾“å‡ºæ ¼å¼')
@click.option('--directory', type=click.Path(exists=True), default='data', help='æ•°æ®ç›®å½•')
@click.pass_context
def data_list(ctx, format, directory):
    """åˆ—å‡ºå·²æœ‰æ•°æ®

    ç¤ºä¾‹:
        ./run_cli.sh data list
        ./run_cli.sh data list --format json
        ./run_cli.sh data list --directory data/cache
    """
    import os
    import pandas as pd
    from pathlib import Path

    data_dir = Path(directory)

    if not data_dir.exists():
        click.echo(f"âœ— æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}", err=True)
        return

    # æ‰«æCSV/Parquetæ–‡ä»¶
    files = []
    for ext in ['*.csv', '*.parquet', '*.pkl']:
        files.extend(data_dir.glob(ext))

    if not files:
        click.echo(f"âœ“ æ•°æ®ç›®å½• {data_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return

    # æ”¶é›†æ–‡ä»¶ä¿¡æ¯
    data_info = []
    for file in files:
        stat = file.stat()
        info = {
            'filename': file.name,
            'size_mb': round(stat.st_size / 1024 / 1024, 2),
            'modified': pd.Timestamp(stat.st_mtime, unit='s').strftime('%Y-%m-%d %H:%M:%S'),
            'type': file.suffix[1:]
        }

        # å°è¯•è¯»å–å‰å‡ è¡Œæ¨æ–­å†…å®¹
        try:
            if file.suffix == '.csv':
                df = pd.read_csv(file, nrows=1)
                info['rows'] = '(ä¼°ç®—)'
                info['columns'] = len(df.columns)
                if 'stock_code' in df.columns:
                    info['stock_code'] = df['stock_code'].iloc[0]
            elif file.suffix == '.parquet':
                df = pd.read_parquet(file)
                info['rows'] = len(df)
                info['columns'] = len(df.columns)
        except:
            pass

        data_info.append(info)

    # æ ¼å¼åŒ–è¾“å‡º
    if format == 'json':
        import json
        click.echo(json.dumps(data_info, indent=2, ensure_ascii=False))
    elif format == 'csv':
        df = pd.DataFrame(data_info)
        click.echo(df.to_csv(index=False))
    else:  # table
        df = pd.DataFrame(data_info)
        click.echo(f"\nğŸ“Š æ•°æ®ç›®å½•: {data_dir}\n")
        click.echo(df.to_string(index=False))
        click.echo(f"\næ€»è®¡: {len(files)} ä¸ªæ–‡ä»¶")
```

**éªŒè¯**:
```bash
./run_cli.sh data list
./run_cli.sh data list --format json
```

---

### ä»»åŠ¡2: æ¨¡å‹è®­ç»ƒè¶…å‚æ•°é…ç½® ğŸŸ¡ P2

**ä½ç½®**: [src/controllers/cli/commands/model.py:232](../src/controllers/cli/commands/model.py#L232)

**å½“å‰çŠ¶æ€**:
```python
# Line 232: å§‹ç»ˆä½¿ç”¨ç©ºè¶…å‚å­—å…¸
model = Model(
    model_type=ModelType(type.upper()),
    hyperparameters={}  # âŒ ç¡¬ç¼–ç ç©ºå­—å…¸
)
```

**é—®é¢˜æè¿°**:
- æ— æ³•ä»å‘½ä»¤è¡Œæˆ–é…ç½®æ–‡ä»¶ä¼ å…¥è¶…å‚æ•°
- æ‰€æœ‰æ¨¡å‹ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ

**å½±å“èŒƒå›´**: ğŸŸ¡ **ä¸­**
- å½±å“æ¨¡å‹è°ƒä¼˜èƒ½åŠ›
- ç”¨æˆ·æ— æ³•å®éªŒä¸åŒè¶…å‚æ•°ç»„åˆ

**å»ºè®®å®ç°** (é¢„è®¡20åˆ†é’Ÿ):

```python
# æ·»åŠ å‘½ä»¤è¡Œé€‰é¡¹
@model_group.command(name="train")
@click.option('--type', type=click.Choice(['LGBM', 'MLP', 'LSTM', 'GRU']), required=True)
@click.option('--name', required=True, help='æ¨¡å‹åç§°')
@click.option('--code', help='è‚¡ç¥¨ä»£ç ')
@click.option('--index', help='æŒ‡æ•°åç§°')
@click.option('--start', required=True, help='å¼€å§‹æ—¥æœŸ')
@click.option('--end', required=True, help='ç»“æŸæ—¥æœŸ')
@click.option('--max-stocks', type=int, help='æœ€å¤§è‚¡ç¥¨æ•°é‡')
@click.option('--hyperparameters', type=str, help='è¶…å‚æ•°JSONå­—ç¬¦ä¸²')  # âœ… æ–°å¢
@click.option('--config', type=click.Path(exists=True), help='é…ç½®æ–‡ä»¶è·¯å¾„')
@click.pass_context
async def model_train(ctx, type, name, code, index, start, end, max_stocks, hyperparameters, config):
    """è®­ç»ƒæ¨¡å‹"""

    # åŠ è½½è¶…å‚æ•°
    hyperparams = {}

    # 1. ä»é…ç½®æ–‡ä»¶åŠ è½½(å¦‚æœæä¾›)
    if config:
        config_data = container.config_loader.load_config(config)
        hyperparams = config_data.get('hyperparameters', {})

    # 2. ä»å‘½ä»¤è¡Œè¦†ç›–(å¦‚æœæä¾›)
    if hyperparameters:
        import json
        try:
            cli_hyperparams = json.loads(hyperparameters)
            hyperparams.update(cli_hyperparams)
        except json.JSONDecodeError as e:
            click.echo(f"âœ— è¶…å‚æ•°JSONè§£æå¤±è´¥: {e}", err=True)
            return

    # 3. ä½¿ç”¨æ¨¡å‹ç±»å‹é»˜è®¤å€¼(å¦‚æœéƒ½æ²¡æä¾›)
    if not hyperparams:
        hyperparams = get_default_hyperparameters(type)

    click.echo(f"â„¹ ä½¿ç”¨è¶…å‚æ•°: {hyperparams}")

    # åˆ›å»ºæ¨¡å‹
    model = Model(
        model_type=ModelType(type.upper()),
        hyperparameters=hyperparams
    )

    # ... ç»§ç»­è®­ç»ƒé€»è¾‘

def get_default_hyperparameters(model_type: str) -> dict:
    """è·å–æ¨¡å‹é»˜è®¤è¶…å‚æ•°"""
    defaults = {
        'LGBM': {
            'n_estimators': 100,
            'learning_rate': 0.05,
            'max_depth': 7,
            'num_leaves': 31,
            'min_child_samples': 20
        },
        'MLP': {
            'hidden_layers': [64, 32],
            'activation': 'relu',
            'learning_rate': 0.001,
            'epochs': 50
        },
        'LSTM': {
            'hidden_size': 64,
            'num_layers': 2,
            'sequence_length': 20,
            'learning_rate': 0.001,
            'epochs': 50
        }
    }
    return defaults.get(model_type.upper(), {})
```

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
# ä½¿ç”¨é»˜è®¤è¶…å‚æ•°
./run_cli.sh model train --type LGBM --name test1 --code sh600036 --start 2023-01-01 --end 2023-12-31

# ä½¿ç”¨è‡ªå®šä¹‰è¶…å‚æ•°
./run_cli.sh model train --type LGBM --name test2 --code sh600036 --start 2023-01-01 --end 2023-12-31 \
  --hyperparameters '{"n_estimators": 200, "learning_rate": 0.03}'

# ä½¿ç”¨é…ç½®æ–‡ä»¶
./run_cli.sh model train --type LGBM --name test3 --code sh600036 --start 2023-01-01 --end 2023-12-31 \
  --config config/lgbm_tuned.yaml
```

---

### ä»»åŠ¡3: `model list` å’Œ `model delete` å®ç° ğŸŸ¡ P2

**ä½ç½®**:
- [src/controllers/cli/commands/model.py:287](../src/controllers/cli/commands/model.py#L287) - model list
- [src/controllers/cli/commands/model.py:336](../src/controllers/cli/commands/model.py#L336) - model delete

**å½“å‰çŠ¶æ€**:
```python
# Line 287
@model_group.command(name="list")
def model_list():
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹"""
    # TODO: å®ç°åˆ—å‡ºæ‰€æœ‰æ¨¡å‹çš„é€»è¾‘
    click.echo("âœ… åˆ—å‡ºæ‰€æœ‰æ¨¡å‹åŠŸèƒ½å°šæœªå®ç°")

# Line 336
@model_group.command(name="delete")
@click.argument('model_id')
def model_delete(model_id):
    """åˆ é™¤æŒ‡å®šæ¨¡å‹"""
    # TODO: å®ç°åˆ é™¤æ¨¡å‹çš„é€»è¾‘
    click.echo(f"âœ… åˆ é™¤æ¨¡å‹ {model_id} åŠŸèƒ½å°šæœªå®ç°")
```

**é—®é¢˜æè¿°**:
- æ— æ³•æŸ¥çœ‹å·²è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨
- æ— æ³•åˆ é™¤æ—§æ¨¡å‹é‡Šæ”¾å­˜å‚¨ç©ºé—´

**å½±å“èŒƒå›´**: ğŸŸ¡ **ä¸­**
- å½±å“æ¨¡å‹ç®¡ç†èƒ½åŠ›
- å­˜å‚¨ç©ºé—´å¯èƒ½è¢«å†å²æ¨¡å‹å ç”¨

**å»ºè®®å®ç°** (é¢„è®¡30åˆ†é’Ÿ):

```python
@model_group.command(name="list")
@click.option('--format', type=click.Choice(['table', 'json', 'csv']), default='table')
@click.option('--status', type=click.Choice(['TRAINED', 'UNTRAINED', 'DEPLOYED', 'ARCHIVED']), help='ç­›é€‰çŠ¶æ€')
@click.option('--type', type=click.Choice(['LGBM', 'MLP', 'LSTM', 'GRU']), help='ç­›é€‰æ¨¡å‹ç±»å‹')
@click.option('--limit', type=int, default=20, help='è¿”å›æ•°é‡é™åˆ¶')
@click.pass_context
async def model_list(ctx, format, status, type, limit):
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹

    ç¤ºä¾‹:
        ./run_cli.sh model list
        ./run_cli.sh model list --format json
        ./run_cli.sh model list --status TRAINED --type LGBM
        ./run_cli.sh model list --limit 10
    """
    container = ctx.obj
    model_repository = container.model_repository

    try:
        await model_repository.initialize()

        # ä»SQLiteæ•°æ®åº“è¯»å–æ¨¡å‹åˆ—è¡¨
        # TODO: éœ€è¦åœ¨SQLiteModelRepositoryæ·»åŠ list_modelsæ–¹æ³•
        models = await model_repository.list_models(
            status=status,
            model_type=type,
            limit=limit
        )

        if not models:
            click.echo("âœ“ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹")
            return

        # æ ¼å¼åŒ–æ¨¡å‹ä¿¡æ¯
        models_info = []
        for model in models:
            info = {
                'id': model.id[:8],  # æ˜¾ç¤ºå‰8ä½
                'name': model.name if hasattr(model, 'name') else '-',
                'type': model.model_type.value,
                'status': model.status.value,
                'training_date': model.training_date.strftime('%Y-%m-%d') if model.training_date else '-',
                'train_r2': f"{model.metrics.get('train_r2', 0):.4f}" if model.metrics else '-',
                'valid_r2': f"{model.metrics.get('valid_r2', 0):.4f}" if model.metrics else '-'
            }
            models_info.append(info)

        # è¾“å‡º
        if format == 'json':
            import json
            click.echo(json.dumps(models_info, indent=2, ensure_ascii=False))
        elif format == 'csv':
            import pandas as pd
            df = pd.DataFrame(models_info)
            click.echo(df.to_csv(index=False))
        else:  # table
            import pandas as pd
            df = pd.DataFrame(models_info)
            click.echo(f"\nğŸ“Š å·²è®­ç»ƒæ¨¡å‹åˆ—è¡¨ (å…± {len(models)} ä¸ª)\n")
            click.echo(df.to_string(index=False))

    except Exception as e:
        click.echo(f"âœ— åˆ—å‡ºæ¨¡å‹å¤±è´¥: {e}", err=True)
    finally:
        await model_repository.close()

@model_group.command(name="delete")
@click.argument('model_id')
@click.option('--force', is_flag=True, help='å¼ºåˆ¶åˆ é™¤,ä¸è¯¢é—®')
@click.pass_context
async def model_delete(ctx, model_id, force):
    """åˆ é™¤æŒ‡å®šæ¨¡å‹

    ç¤ºä¾‹:
        ./run_cli.sh model delete abc12345
        ./run_cli.sh model delete abc12345 --force
    """
    container = ctx.obj
    model_repository = container.model_repository

    try:
        await model_repository.initialize()

        # æŸ¥æ‰¾æ¨¡å‹
        model = await model_repository.get_by_id(model_id)

        if not model:
            click.echo(f"âœ— æ¨¡å‹ä¸å­˜åœ¨: {model_id}", err=True)
            return

        # ç¡®è®¤åˆ é™¤
        if not force:
            click.echo(f"æ¨¡å‹ä¿¡æ¯:")
            click.echo(f"  ID: {model.id}")
            click.echo(f"  ç±»å‹: {model.model_type.value}")
            click.echo(f"  çŠ¶æ€: {model.status.value}")
            click.echo(f"  è®­ç»ƒæ—¥æœŸ: {model.training_date}")

            if not click.confirm('ç¡®è®¤åˆ é™¤æ­¤æ¨¡å‹?'):
                click.echo("âœ“ å–æ¶ˆåˆ é™¤")
                return

        # åˆ é™¤æ¨¡å‹
        await model_repository.delete(model_id)
        click.echo(f"âœ“ æ¨¡å‹ {model_id} å·²åˆ é™¤")

    except Exception as e:
        click.echo(f"âœ— åˆ é™¤æ¨¡å‹å¤±è´¥: {e}", err=True)
    finally:
        await model_repository.close()
```

**éœ€è¦åœ¨SQLiteModelRepositoryæ·»åŠ çš„æ–¹æ³•**:

```python
# src/adapters/repositories/sqlite_model_repository.py

async def list_models(
    self,
    status: Optional[str] = None,
    model_type: Optional[str] = None,
    limit: int = 100
) -> List[Model]:
    """åˆ—å‡ºæ¨¡å‹"""
    conn = await self._get_connection()

    query = "SELECT * FROM models WHERE 1=1"
    params = []

    if status:
        query += " AND status = ?"
        params.append(status)

    if model_type:
        query += " AND model_type = ?"
        params.append(model_type)

    query += " ORDER BY created_at DESC LIMIT ?"
    params.append(limit)

    cursor = await conn.execute(query, params)
    rows = await cursor.fetchall()

    models = []
    for row in rows:
        model = self._deserialize_model(dict(row))
        models.append(model)

    return models

async def delete(self, model_id: str) -> None:
    """åˆ é™¤æ¨¡å‹"""
    conn = await self._get_connection()
    await conn.execute("DELETE FROM models WHERE id = ?", (model_id,))
    await conn.commit()
```

---

### ä»»åŠ¡4: `config set` æŒä¹…åŒ– ğŸŸ¢ P3

**ä½ç½®**: [src/controllers/cli/commands/config.py:93](../src/controllers/cli/commands/config.py#L93)

**å½“å‰çŠ¶æ€**:
```python
@config_group.command(name="set")
@click.argument('key')
@click.argument('value')
def config_set(key, value):
    """è®¾ç½®é…ç½®é¡¹"""
    # TODO: å®ç°è®¾ç½®é…ç½®é¡¹çš„é€»è¾‘
    click.echo(f"âœ… è®¾ç½®é…ç½®é¡¹ {key} = {value} åŠŸèƒ½å°šæœªå®ç°")
```

**é—®é¢˜æè¿°**:
- å‘½ä»¤åªæ‰“å°ä¿¡æ¯,ä¸çœŸæ­£ä¿®æ”¹é…ç½®æ–‡ä»¶
- ç”¨æˆ·æ— æ³•é€šè¿‡CLIåŠ¨æ€ä¿®æ”¹é…ç½®

**å½±å“èŒƒå›´**: ğŸŸ¢ **ä½**
- ç”¨æˆ·å¯ç›´æ¥ç¼–è¾‘config.yaml
- ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½

**å»ºè®®å®ç°** (é¢„è®¡20åˆ†é’Ÿ):

```python
@config_group.command(name="set")
@click.argument('key')
@click.argument('value')
@click.option('--config', type=click.Path(), default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
@click.option('--type', type=click.Choice(['str', 'int', 'float', 'bool', 'json']), default='str', help='å€¼ç±»å‹')
def config_set(key, value, config, type):
    """è®¾ç½®é…ç½®é¡¹

    æ”¯æŒç‚¹å·åˆ†éš”çš„åµŒå¥—é”®,å¦‚: data_source.hikyuu_dir

    ç¤ºä¾‹:
        ./run_cli.sh config set data_source.hikyuu_dir /path/to/hikyuu
        ./run_cli.sh config set training.n_estimators 200 --type int
        ./run_cli.sh config set training.learning_rate 0.03 --type float
        ./run_cli.sh config set training.early_stopping true --type bool
        ./run_cli.sh config set training.params '{"a": 1}' --type json
    """
    import yaml
    from pathlib import Path

    config_path = Path(config)

    if not config_path.exists():
        click.echo(f"âœ— é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}", err=True)
        return

    # è¯»å–é…ç½®
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f) or {}
    except Exception as e:
        click.echo(f"âœ— è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}", err=True)
        return

    # ç±»å‹è½¬æ¢
    try:
        if type == 'int':
            value = int(value)
        elif type == 'float':
            value = float(value)
        elif type == 'bool':
            value = value.lower() in ('true', 'yes', '1', 'on')
        elif type == 'json':
            import json
            value = json.loads(value)
        # else: str, ä¿æŒåŸæ ·
    except Exception as e:
        click.echo(f"âœ— å€¼ç±»å‹è½¬æ¢å¤±è´¥: {e}", err=True)
        return

    # è®¾ç½®åµŒå¥—é”®
    keys = key.split('.')
    current = config_data

    for k in keys[:-1]:
        if k not in current:
            current[k] = {}
        current = current[k]

    current[keys[-1]] = value

    # å†™å›é…ç½®æ–‡ä»¶
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, allow_unicode=True, default_flow_style=False)

        click.echo(f"âœ“ å·²è®¾ç½® {key} = {value}")
        click.echo(f"âœ“ é…ç½®å·²ä¿å­˜åˆ° {config_path}")

    except Exception as e:
        click.echo(f"âœ— ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}", err=True)
```

---

### ä»»åŠ¡5: `predict` æ–¹æ³•å®ç° ğŸŸ¡ P1

**ä½ç½®**: [src/adapters/qlib/qlib_model_trainer_adapter.py:212-236](../src/adapters/qlib/qlib_model_trainer_adapter.py#L212-L236)

**å½“å‰çŠ¶æ€**:
```python
async def predict(self, model: Model, input_data: Any) -> List[Prediction]:
    """
    ç”Ÿæˆé¢„æµ‹

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        input_data: è¾“å…¥æ•°æ®(å¯ä»¥æ˜¯DataFrameæˆ–KLineDataåˆ—è¡¨)

    Returns:
        List[Prediction]: é¢„æµ‹ç»“æœåˆ—è¡¨
    """
    # TODO: å®ç°é¢„æµ‹é€»è¾‘
    return []  # âŒ ç©ºå£³å®ç°
```

**é—®é¢˜æè¿°**:
- predictæ–¹æ³•å®Œå…¨æœªå®ç°
- æ— æ³•ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆé¢„æµ‹
- **é˜»å¡åç»­ä¿¡å·è½¬æ¢å’Œå›æµ‹æµç¨‹**

**å½±å“èŒƒå›´**: ğŸ”´ **é«˜**
- **é˜»å¡å®Œæ•´å·¥ä½œæµ**
- é¢„æµ‹â†’ä¿¡å·â†’å›æµ‹é“¾æ¡æ–­è£‚

**å»ºè®®å®ç°** (é¢„è®¡1å°æ—¶):

```python
async def predict(self, model: Model, input_data: Any) -> List[Prediction]:
    """
    ç”Ÿæˆé¢„æµ‹

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        input_data: è¾“å…¥æ•°æ®(å¯ä»¥æ˜¯DataFrameæˆ–KLineDataåˆ—è¡¨)

    Returns:
        List[Prediction]: é¢„æµ‹ç»“æœåˆ—è¡¨
    """
    if not isinstance(input_data, pd.DataFrame):
        # å¦‚æœæ˜¯KLineDataåˆ—è¡¨,å…ˆè½¬æ¢ä¸ºDataFrame
        from utils.data_conversion import convert_kline_to_training_data
        input_data = convert_kline_to_training_data(
            input_data,
            add_features=True,
            add_labels=False  # é¢„æµ‹æ—¶ä¸éœ€è¦æ ‡ç­¾
        )

    if input_data.empty:
        raise ValueError("Input data is empty")

    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
    if model.status != ModelStatus.TRAINED:
        raise ValueError(f"Model status is {model.status}, expected TRAINED")

    # å‡†å¤‡ç‰¹å¾
    exclude_cols = ['stock_code', 'timestamp', 'label_return', 'label_direction', 'label_multiclass']
    feature_cols = [col for col in input_data.columns if col not in exclude_cols]

    if not feature_cols:
        raise ValueError("No feature columns found in input data")

    X = input_data[feature_cols].fillna(0)

    # ç”Ÿæˆé¢„æµ‹
    try:
        predictions_array = self._model.predict(X)
    except Exception as e:
        raise RuntimeError(f"Model prediction failed: {e}")

    # è½¬æ¢ä¸ºPredictionå®ä½“åˆ—è¡¨
    from domain.entities.prediction import Prediction
    from domain.value_objects.stock_code import StockCode
    from decimal import Decimal

    predictions = []
    for i, pred_value in enumerate(predictions_array):
        # è·å–å¯¹åº”çš„è¡Œä¿¡æ¯
        row = input_data.iloc[i]

        prediction = Prediction(
            stock_code=StockCode(row.get('stock_code', 'unknown')),
            prediction_date=row.get('timestamp', pd.Timestamp.now()),
            predicted_value=Decimal(str(pred_value)),
            confidence=self._calculate_confidence(pred_value, predictions_array),
            model_id=model.id,
            features=dict(zip(feature_cols, X.iloc[i].values))  # ä¿å­˜è¾“å…¥ç‰¹å¾
        )
        predictions.append(prediction)

    return predictions

def _calculate_confidence(self, value: float, all_values: np.ndarray) -> Decimal:
    """
    æ ¹æ®é¢„æµ‹å€¼åœ¨å…¨ä½“åˆ†å¸ƒä¸­çš„ä½ç½®è®¡ç®—ç½®ä¿¡åº¦

    ç½®ä¿¡åº¦è®¡ç®—é€»è¾‘:
    - é¢„æµ‹å€¼è¶Šæ¥è¿‘æç«¯å€¼(æœ€é«˜æˆ–æœ€ä½),ç½®ä¿¡åº¦è¶Šé«˜
    - é¢„æµ‹å€¼æ¥è¿‘ä¸­ä½æ•°,ç½®ä¿¡åº¦è¾ƒä½
    """
    if len(all_values) < 2:
        return Decimal("0.5")

    # è®¡ç®—ç™¾åˆ†ä½
    percentile = scipy.stats.percentileofscore(all_values, value)

    # è½¬æ¢ä¸ºç½®ä¿¡åº¦: 0-50%æ˜ å°„åˆ°0.5-1.0, 50-100%æ˜ å°„åˆ°1.0-0.5
    if percentile <= 50:
        confidence = 0.5 + (50 - percentile) / 100  # 0-50% -> 1.0-0.5
    else:
        confidence = 0.5 + (percentile - 50) / 100  # 50-100% -> 0.5-1.0

    return Decimal(str(round(confidence, 4)))
```

**éªŒè¯**:
```python
# æµ‹è¯•è„šæœ¬
import asyncio
from domain.entities.model import Model, ModelType, ModelStatus
from adapters.qlib.qlib_model_trainer_adapter import QlibModelTrainerAdapter
import pandas as pd

async def test_predict():
    # åˆ›å»ºæµ‹è¯•æ¨¡å‹
    model = Model(
        model_type=ModelType.LGBM,
        hyperparameters={'n_estimators': 50}
    )
    model.status = ModelStatus.TRAINED

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'stock_code': ['sh600036'] * 10,
        'timestamp': pd.date_range('2024-01-01', periods=10),
        'ma5': [10.0 + i for i in range(10)],
        'ma10': [10.5 + i for i in range(10)],
        'return': [0.01 * i for i in range(10)]
    })

    # é¢„æµ‹
    trainer = QlibModelTrainerAdapter()
    predictions = await trainer.predict(model, test_data)

    print(f"âœ“ ç”Ÿæˆ {len(predictions)} ä¸ªé¢„æµ‹")
    for pred in predictions[:3]:
        print(f"  {pred.stock_code.value} @ {pred.prediction_date}: {pred.predicted_value} (ç½®ä¿¡åº¦: {pred.confidence})")

asyncio.run(test_predict())
```

---

### ä»»åŠ¡6: è®­ç»ƒæ•°æ®ç¼“å­˜æœºåˆ¶ ğŸŸ¢ P3

**ä½ç½®**: [docs/model_training_data_flow.py:64-76](../docs/model_training_data_flow.py#L64-L76)

**å½“å‰çŠ¶æ€**:
```python
# Line 64-76
if use_cache:
    # ä»æ•°æ®åº“ç¼“å­˜è¯»å–è®­ç»ƒæ•°æ®
    cached_data = await training_data_cache.get(
        stock_codes=stock_codes,
        date_range=date_range,
        feature_config=feature_config
    )
    if cached_data:
        return cached_data
    else:
        raise NotImplementedError("ç¼“å­˜åŠŸèƒ½å°šæœªå®ç°")  # âŒ æœªå®ç°
```

**é—®é¢˜æè¿°**:
- æ¯æ¬¡è®­ç»ƒéƒ½é‡æ–°åŠ è½½å’Œè®¡ç®—ç‰¹å¾
- å¤§é‡é‡å¤è®¡ç®—,æµªè´¹æ—¶é—´
- å¯¹äºæŒ‡æ•°æˆåˆ†è‚¡è®­ç»ƒå°¤å…¶è€—æ—¶

**å½±å“èŒƒå›´**: ğŸŸ¢ **ä½**
- ä¸å½±å“åŠŸèƒ½æ­£ç¡®æ€§
- å½±å“æ‰¹é‡è®­ç»ƒæ•ˆç‡

**å»ºè®®å®ç°** (é¢„è®¡2å°æ—¶):

è¿™ä¸ªä»»åŠ¡è¾ƒå¤æ‚,æ¶‰åŠ:
1. è®¾è®¡ç¼“å­˜è¡¨ç»“æ„
2. å®ç°ç¼“å­˜DAO(Data Access Object)
3. å®ç°ç¼“å­˜å‘½ä¸­å’Œå¤±æ•ˆé€»è¾‘
4. é›†æˆåˆ°è®­ç»ƒæµç¨‹

**å»ºè®®æš‚æ—¶ä¸å®ç°**,ç†ç”±:
- P3ä½ä¼˜å…ˆçº§
- MVPé˜¶æ®µè®­ç»ƒé‡ä¸å¤§
- å¯åœ¨P2é˜¶æ®µå®ç°
- å½“å‰ç”¨æˆ·å¯æ‰‹åŠ¨ä¿å­˜CSVå¤ç”¨

---

## ä¼˜å…ˆçº§å»ºè®®

### ğŸ”´ P1 (å¿…é¡»å®æ–½,é˜»å¡æ ¸å¿ƒåŠŸèƒ½)

1. **ä»»åŠ¡5: predictæ–¹æ³•å®ç°** (1å°æ—¶)
   - é˜»å¡é¢„æµ‹â†’ä¿¡å·â†’å›æµ‹å®Œæ•´é“¾æ¡
   - å¿…é¡»åœ¨å‘å¸ƒMVPå‰å®Œæˆ

### ğŸŸ¡ P2 (å»ºè®®å®æ–½,æå‡ç”¨æˆ·ä½“éªŒ)

2. **ä»»åŠ¡3: model list/delete** (30åˆ†é’Ÿ)
   - æå‡æ¨¡å‹ç®¡ç†èƒ½åŠ›
   - ç”¨æˆ·é«˜é¢‘ä½¿ç”¨åœºæ™¯

3. **ä»»åŠ¡2: è¶…å‚æ•°é…ç½®** (20åˆ†é’Ÿ)
   - æå‡æ¨¡å‹è°ƒä¼˜èƒ½åŠ›
   - å®éªŒè¿­ä»£å¿…éœ€

4. **ä»»åŠ¡1: data list** (30åˆ†é’Ÿ)
   - æ–¹ä¾¿æ•°æ®ç®¡ç†
   - é™ä½å­¦ä¹ æˆæœ¬

### ğŸŸ¢ P3 (å¯é€‰å®æ–½,é”¦ä¸Šæ·»èŠ±)

5. **ä»»åŠ¡4: config setæŒä¹…åŒ–** (20åˆ†é’Ÿ)
   - ç”¨æˆ·å¯ç›´æ¥ç¼–è¾‘YAML
   - éåˆšéœ€

6. **ä»»åŠ¡6: è®­ç»ƒæ•°æ®ç¼“å­˜** (2å°æ—¶+)
   - ä»…å¤§è§„æ¨¡è®­ç»ƒæ—¶æœ‰ä»·å€¼
   - å¯åç»­ä¼˜åŒ–

---

## å®æ–½è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µ (ç«‹å³å®æ–½,1å°æ—¶)

**ç›®æ ‡**: è§£é™¤P1é˜»å¡,å®ç°å®Œæ•´å·¥ä½œæµ

- [ ] ä»»åŠ¡5: å®ç°predictæ–¹æ³• (1å°æ—¶)
- [ ] éªŒè¯å®Œæ•´æµç¨‹: æ•°æ®â†’è®­ç»ƒâ†’é¢„æµ‹â†’ä¿¡å·â†’å›æµ‹

### ç¬¬äºŒé˜¶æ®µ (æœ¬å‘¨å†…,1.5å°æ—¶)

**ç›®æ ‡**: æå‡ç”¨æˆ·ä½“éªŒ

- [ ] ä»»åŠ¡3: å®ç°model list/delete (30åˆ†é’Ÿ)
- [ ] ä»»åŠ¡2: å®ç°è¶…å‚æ•°é…ç½® (20åˆ†é’Ÿ)
- [ ] ä»»åŠ¡1: å®ç°data list (30åˆ†é’Ÿ)
- [ ] æ›´æ–°CLIæ–‡æ¡£

### ç¬¬ä¸‰é˜¶æ®µ (P2è¿­ä»£,å¯é€‰)

**ç›®æ ‡**: å®Œå–„è¾…åŠ©åŠŸèƒ½

- [ ] ä»»åŠ¡4: config setæŒä¹…åŒ– (20åˆ†é’Ÿ)
- [ ] ä»»åŠ¡6: è®­ç»ƒæ•°æ®ç¼“å­˜ (2å°æ—¶+)

---

## ä¾èµ–å…³ç³»

```
ä»»åŠ¡5 (predict)
  â†“ [é˜»å¡]
CLIé›†æˆ (model predictå‘½ä»¤)
  â†“ [é˜»å¡]
å®Œæ•´å·¥ä½œæµéªŒè¯
  â†“
MVPå‘å¸ƒ

ä»»åŠ¡2/3 (è¶…å‚æ•°/æ¨¡å‹ç®¡ç†)
  â†“ [æå‡]
ç”¨æˆ·ä½“éªŒ

ä»»åŠ¡1/4 (data list / config set)
  â†“ [å¯é€‰]
ä¾¿åˆ©æ€§åŠŸèƒ½
```

---

## éªŒæ”¶æ ‡å‡†

### ä»»åŠ¡5 (P1)

- [ ] predictæ–¹æ³•è¿”å›éç©ºPredictionåˆ—è¡¨
- [ ] é¢„æµ‹å€¼ç±»å‹æ­£ç¡®(Decimal)
- [ ] ç½®ä¿¡åº¦åœ¨0-1èŒƒå›´å†…
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] é›†æˆåˆ°CLIå‘½ä»¤

### ä»»åŠ¡2 (P2)

- [ ] æ”¯æŒå‘½ä»¤è¡Œä¼ å…¥è¶…å‚æ•°JSON
- [ ] æ”¯æŒé…ç½®æ–‡ä»¶åŠ è½½è¶…å‚æ•°
- [ ] æä¾›æ¨¡å‹ç±»å‹é»˜è®¤å€¼
- [ ] æ–‡æ¡£æ›´æ–°

### ä»»åŠ¡3 (P2)

- [ ] model listæ˜¾ç¤ºå®Œæ•´æ¨¡å‹ä¿¡æ¯
- [ ] æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼(table/json/csv)
- [ ] model deleteåŠŸèƒ½æ­£å¸¸
- [ ] æœ‰ç¡®è®¤æœºåˆ¶é˜²è¯¯åˆ 

### ä»»åŠ¡1 (P2)

- [ ] data listæ‰«ææ•°æ®ç›®å½•
- [ ] æ˜¾ç¤ºæ–‡ä»¶åŸºæœ¬ä¿¡æ¯(å¤§å°ã€ä¿®æ”¹æ—¶é—´)
- [ ] æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼

---

## å‚è€ƒæ–‡æ¡£

- [P0_COMPLETION_REPORT.md](P0_COMPLETION_REPORT.md) - P0å®æ–½æŠ¥å‘Š
- [FEATURE_GAP_ANALYSIS.md](FEATURE_GAP_ANALYSIS.md) - åŠŸèƒ½ç¼ºå£åˆ†æ
- [BUG_FIXES_SUMMARY.md](BUG_FIXES_SUMMARY.md) - Bugä¿®å¤æ€»ç»“

---

**æ–‡æ¡£åˆ›å»ºæ—¥æœŸ**: 2025-11-14
**ä¸‹ä¸€æ­¥**: ç«‹å³å®æ–½ä»»åŠ¡5 (predictæ–¹æ³•),è§£é™¤P1é˜»å¡
